{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Third Edition](https://www.manning.com/books/deep-learning-with-python-third-edition). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "The book's contents are available online at [deeplearningwithpython.io](https://deeplearningwithpython.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!pip install keras keras-hub --upgrade -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "cellView": "form",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import os\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def backend(line, cell):\n",
    "    current, required = os.environ.get(\"KERAS_BACKEND\", \"\"), line.split()[-1]\n",
    "    if current == required:\n",
    "        get_ipython().run_cell(cell)\n",
    "    else:\n",
    "        print(\n",
    "            f\"This cell requires the {required} backend. To run it, change KERAS_BACKEND to \"\n",
    "            f\"\\\"{required}\\\" at the top of the notebook, restart the runtime, and rerun the notebook.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A deep dive on Keras\n",
    "\n",
    "이 장에서는 다음 내용을 다룹니다.\r\n",
    "\r\n",
    "* Keras 모델을 생성하는 다양한 방법: Sequential 클래스, Functional API 및 모델 서브클래싱\r\n",
    "* 내장된 Keras 학습 및 평가 루프 사용 방법(사용자 지정 메트릭 및 손실 함수 사용 방법 포함)\r\n",
    "* Keras 콜백을 사용하여 학습 진행 방식을 더욱 세밀하게 사용자 지정하는 방법\r\n",
    "* TensorBoard를 사용하여 학습 및 평가 메트릭을 시간에 따라 모니터링하는 방법\r\n",
    "* 학습 및 평가 루프를 처음부터 직접 작\n",
    "\n",
    "이제 Keras를 어느 정도 경험해 보셨을 겁니다. Sequential 모델, Dense 레이어, 그리고 학습, 평가, 추론을 위한 내장 API(compile(), fit(), evaluate(), predict())에 익숙해지셨을 것입니다. 3장에서는 Layer 클래스를 상속받아 사용자 정의 레이어를 만드는 방법과 TensorFlow, JAX, PyTorch의 그래디언트 API를 사용하여 단계별 학습 루프를 구현하는 방법도 배웠습니다.\r\n",
    "\r\n",
    "다음 장에서는 컴퓨터 비전, 시계열 예측, 자연어 처리, 생성형 딥러닝을 자세히 살펴보겠습니다. 이러한 복잡한 애플리케이션을 구현하려면 Sequential 아키텍처와 기본 fit() 루프만으로는 부족합니다. 그러니 먼저 여러분을 Keras 전문가로 만들어 봅시다! 이 장에서는 Keras API를 사용하는 핵심적인 방법들을 완벽하게 개괄적으로 살펴보겠습니다. 앞으로 접하게 될 고급 딥러닝 사용 사례들을 처리하는 데 필요한 모든 것을 배우게 될 것입니다.성하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A spectrum of workflows\n",
    "\n",
    "케라스 API의 설계는 복잡성의 점진적 공개라는 원칙에 따라 이루어졌습니다. 즉, 쉽게 시작할 수 있도록 하면서도, 각 단계에서 점진적인 학습만으로 복잡한 사용 사례도 처리할 수 있도록 하는 것입니다. 간단한 사용 사례는 쉽고 접근하기 쉬워야 하며, 고급 워크플로도 가능해야 합니다. 아무리 전문적이고 복잡한 작업을 수행하더라도, 그 목표에 도달하는 명확한 경로가 있어야 하며, 이 경로는 간단한 워크플로에서 학습한 다양한 요소들을 기반으로 구축되어야 합니다. 이는 초보자에서 전문가로 성장하더라도 동일한 도구를 다양한 방식으로 사용할 수 있음을 의미합니다.\r\n",
    "\r\n",
    "따라서 케라스를 사용하는 단 하나의 \"정답\"은 없습니다. 케라스는 매우 간단한 워크플로부터 매우 유연한 워크플로까지 다양한 워크플로를 제공합니다. 케라스 모델을 구축하는 방법과 학습시키는 방법 또한 다양하며, 각각 다른 요구 사항을 충족합니다.\r\n",
    "\r\n",
    "예를 들어, 모델을 구축하는 다양한 방법과 학습시키는 다양한 방법이 있으며, 각 방법은 사용 편의성과 유연성 사이의 특정 절충점을 나타냅니다. 케라스를 마치 scikit-learn처럼 `fit()` 메서드만 호출하고 프레임워크가 알아서 처리하도록 둘 수도 있고, NumPy처럼 모든 세부 사항을 직접 제어하며 사용할 수도 있습니다.\r\n",
    "\r\n",
    "이러한 워크플로는 모두 `Layer`와 `Model` 같은 공유 API를 기반으로 하기 때문에 어떤 워크플로의 구성 요소든 다른 워크플로에서 사용할 수 있습니다. 즉, 모든 워크플로가 서로 연동됩니다. 따라서 지금 배우는 모든 내용은 전문가가 된 후에도 여전히 유용합니다. 쉽게 시작해서 점차 더 복잡한 로직을 직접 작성하는 워크플로로 나아갈 수 있습니다. 학생에서 연구원으로, 또는 데이터 과학자에서 딥러닝 엔지니어로 성장한다고 해서 완전히 다른 프레임워크로 갈아탈 필요가 없습니다.\r\n",
    "\r\n",
    "이러한 철학은 파이썬 자체의 철학과도 같습니다! 어떤 언어는 객체 지향 프로그래밍이나 함수형 프로그래밍처럼 프로그램을 작성하는 한 가지 방법만 제공합니다. 하지만 파이썬은 다양한 패러다임을 지원하는 언어입니다. 다양한 사용 패턴을 제공하며, 이 패턴들은 서로 조화롭게 작동합니다. 이러한 특징 덕분에 파이썬은 시스템 관리, 데이터 과학, 머신러닝 엔지니어링, 웹 개발, 심지어 프로그래밍 학습에 이르기까지 매우 다양한 용도에 적합합니다. 마찬가지로 케라스는 딥러닝 분야의 파이썬이라고 생각할 수 있습니다. 사용자 친화적인 딥러닝 언어로서 다양한 사용자 프로필에 맞는 여러 워크플로우를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different ways to build Keras models\r\n",
    "그림 7.1에서 보는 것처럼 Keras에서 모델을 구축하는 데에는 세 가지 API가 있습니다.\r\n",
    "\r\n",
    "Sequential 모델은 가장 접근하기 쉬운 API로, 기본적으로 파이썬 리스트와 같습니다. 따라서 간단한 레이어 스택으로 제한됩니다.\r\n",
    "Functional API는 그래프 형태의 모델 아키텍처에 초점을 맞춥니다. 사용성과 유연성의 균형을 잘 맞춰주기 때문에 가장 일반적으로 사용되는 모델 구축 API입니다.\r\n",
    "모델 서브클래싱은 모든 것을 처음부터 직접 작성하는 저수준 옵션입니다. 모든 세부 사항을 완벽하게 제어하고 싶을 때 이상적입니다. 하지만 Keras의 내장 기능을 많이 사용할 수 없고, 오류 발생 위험도 더 높습니다.\r\n",
    "\r\n",
    "<img src=\"https://deeplearningwithpython.io/images/ch07/progressive_disclosure_of_complexity_models.f43bcdb0.png\" width=\"600\"><p style=\"text-align:center\">Figure 7.1: Progressive disclosure of complexity for model building</p>\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The Sequential model\n",
    "\n",
    "케라스 모델을 구축하는 가장 간단한 방법은 여러분이 이미 알고 있는 Sequential 모델입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬 리스트의 append() 메서드와 유사하게 add() 메서드를 통해 동일한 모델을 점진적으로 구축할 수 있다는 점에 유의하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3장에서 보셨듯이 레이어는 처음 호출될 때만 생성(즉, 가중치 생성)됩니다. 이는 레이어 가중치의 형태가 입력의 형태에 따라 달라지기 때문입니다. 입력 형태를 알기 전까지는 가중치를 생성할 수 없습니다.\r\n",
    "\r\n",
    "따라서 앞서 살펴본 Sequential 모델은 실제로 데이터를 사용하여 호출하거나, 입력 형태를 지정하여 `build()` 메서드를 호출하기 전까지는 가중치를 갖지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Variable path=sequential_1/dense_2/kernel, shape=(3, 64), dtype=float32, value=[[ 2.54702926e-01  7.62956440e-02  6.15263879e-02  2.37277746e-01\n",
       "    7.42867887e-02  1.50711179e-01  1.09444380e-01  4.88079786e-02\n",
       "   -1.55318573e-01 -2.77410001e-01 -1.70827582e-01 -2.98092335e-01\n",
       "    4.46355343e-03 -5.81276119e-02 -1.00441575e-02 -1.86474070e-01\n",
       "   -1.25022665e-01  2.13086724e-01 -1.83776617e-02  7.35586882e-02\n",
       "   -1.22972935e-01  2.87660658e-02 -1.74186468e-01  1.43654346e-01\n",
       "   -5.75728863e-02 -2.72414684e-01 -2.02964038e-01  6.79664910e-02\n",
       "    1.52969182e-01  1.13277525e-01 -2.25347579e-01  2.47009695e-01\n",
       "    2.45648623e-03 -1.61507323e-01  2.95137823e-01 -2.88452506e-01\n",
       "    1.33629084e-01 -1.22874185e-01 -1.78508908e-01 -1.43452361e-01\n",
       "    9.35935974e-03 -9.60451961e-02  8.78291726e-02 -1.78415656e-01\n",
       "    1.54769987e-01 -5.08776307e-02  1.87758684e-01 -1.67139128e-01\n",
       "    2.50300705e-01 -1.61230713e-01  3.81367803e-02 -3.80921662e-02\n",
       "   -1.70105100e-02 -2.13105142e-01 -4.29670513e-02 -5.25164902e-02\n",
       "   -2.93762416e-01 -1.25050634e-01 -6.64579868e-02 -1.68151051e-01\n",
       "   -1.45060167e-01  2.53481209e-01  9.98550653e-02 -1.60568535e-01]\n",
       "  [-1.02518335e-01  2.75477767e-01 -2.74493814e-01  1.45909280e-01\n",
       "   -9.50592458e-02 -8.81038010e-02  5.86396754e-02  5.00716865e-02\n",
       "   -6.84439391e-02  1.67495877e-01 -1.68158323e-01  2.73749173e-01\n",
       "   -2.34507516e-01 -8.97705555e-02  2.28951454e-01 -8.49611610e-02\n",
       "   -2.44899392e-02  2.49628842e-01  1.10357195e-01 -2.50237912e-01\n",
       "   -2.18904197e-01  8.78889859e-02 -2.32303590e-01 -1.78747565e-01\n",
       "   -3.15034688e-02  9.21310782e-02 -9.62161422e-02 -2.71153122e-01\n",
       "    1.91927224e-01 -1.82505786e-01 -2.99132884e-01  2.00889587e-01\n",
       "   -1.71374381e-01  2.49397635e-01 -2.93590426e-02 -2.93366432e-01\n",
       "   -8.96356255e-02 -1.98129460e-01 -1.94147557e-01  6.61467016e-02\n",
       "   -1.99906945e-01  1.57103032e-01  7.20708966e-02  2.96387970e-01\n",
       "   -2.48990178e-01  2.22793281e-01  1.73493624e-01 -8.57309997e-02\n",
       "   -1.97020084e-01 -2.60433972e-01  1.53283596e-01 -2.74160624e-01\n",
       "    5.86605072e-02 -7.03963637e-03  2.02224255e-01  2.84269750e-01\n",
       "    9.29169655e-02 -5.28949499e-03 -2.18996510e-01 -2.23662138e-01\n",
       "   -1.90209240e-01 -1.88855857e-01  1.59296036e-01 -5.89712858e-02]\n",
       "  [-6.27040863e-05  2.59085417e-01 -1.04040325e-01 -1.34630680e-01\n",
       "   -2.64852941e-02 -1.47618905e-01  1.79668665e-02 -6.72464520e-02\n",
       "    1.77624136e-01  2.33400464e-01 -9.43651050e-02  1.42835498e-01\n",
       "    2.18656600e-01  1.55224681e-01 -2.27567613e-01 -1.09562755e-01\n",
       "   -2.95416087e-01 -1.78677440e-01  2.10733473e-01 -1.52747571e-01\n",
       "   -1.29333913e-01  2.71088600e-01  1.38489008e-01  5.60052991e-02\n",
       "    5.09727299e-02 -2.77346998e-01 -2.35670894e-01  6.54793978e-02\n",
       "    1.53457403e-01 -2.31032610e-01  9.80222225e-03 -2.93503851e-01\n",
       "   -2.09431320e-01  1.50155663e-01 -1.75970793e-03 -2.13647813e-01\n",
       "    1.78528816e-01 -1.39588326e-01 -2.48710930e-01  1.84886247e-01\n",
       "   -2.99165547e-01 -4.72090244e-02 -1.95992172e-01 -6.14605248e-02\n",
       "    1.36780739e-02  1.63541585e-01 -1.03348389e-01  1.02545172e-01\n",
       "    3.98091674e-02  9.74082947e-02 -1.59043550e-01  3.00082266e-02\n",
       "    2.48369515e-01  1.50413424e-01  1.55682147e-01  2.86243558e-01\n",
       "   -2.10101411e-01 -7.81764537e-02 -3.12648714e-02 -6.96599185e-02\n",
       "    1.63780749e-02  1.27266407e-01 -4.52493131e-02  5.60279191e-02]]>,\n",
       " <Variable path=sequential_1/dense_2/bias, shape=(64,), dtype=float32, value=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]>,\n",
       " <Variable path=sequential_1/dense_3/kernel, shape=(64, 10), dtype=float32, value=[[ 1.83271021e-01 -2.06693977e-01  8.33401382e-02 -1.76022843e-01\n",
       "    1.31930113e-02  1.01192176e-01 -4.74931598e-02  3.49602103e-02\n",
       "   -1.86233222e-01 -2.45606840e-01]\n",
       "  [-5.20301163e-02  7.28006363e-02 -1.98367238e-01 -2.31444627e-01\n",
       "   -5.74490875e-02  1.11280650e-01 -1.58449352e-01  1.65464938e-01\n",
       "    1.74746245e-01 -9.55081731e-02]\n",
       "  [-2.77071983e-01  8.47567320e-02 -1.46432579e-01 -7.61456639e-02\n",
       "   -2.66790330e-01 -2.03661233e-01  2.31112629e-01 -3.22729647e-02\n",
       "   -1.02069512e-01 -5.93755096e-02]\n",
       "  [-2.70490199e-01 -8.47695470e-02 -1.44056603e-01  1.69369459e-01\n",
       "   -1.37058735e-01 -3.90026122e-02 -1.38286769e-01  2.12260187e-01\n",
       "   -1.66504323e-01  2.19821066e-01]\n",
       "  [ 6.61804974e-02 -2.33488709e-01 -2.76481628e-01 -1.78408593e-01\n",
       "   -1.66731477e-01  2.54497200e-01 -2.73463756e-01  2.47896820e-01\n",
       "   -2.09375322e-01  6.70561194e-03]\n",
       "  [ 1.88054830e-01 -1.97298408e-01 -1.69327423e-01  9.95988846e-02\n",
       "   -1.91233724e-01 -8.15809369e-02 -1.86742052e-01 -3.62742841e-02\n",
       "   -1.03931233e-01 -2.79659450e-01]\n",
       "  [ 1.48438364e-01  1.08444691e-02  1.61848545e-01 -5.22145033e-02\n",
       "    2.76201516e-01 -1.38550594e-01  1.64652437e-01  8.78265202e-02\n",
       "    1.03568107e-01  1.48191392e-01]\n",
       "  [ 2.71176010e-01  2.49284059e-01  6.43673837e-02  9.17343497e-02\n",
       "   -2.34794483e-01  7.26182163e-02 -2.42037162e-01  2.29802340e-01\n",
       "   -1.04258731e-01 -1.20819524e-01]\n",
       "  [-1.25410318e-01  1.20242476e-01 -1.27882838e-01 -2.62137890e-01\n",
       "   -1.72828943e-01 -2.61886239e-01  1.15482211e-01 -6.93622679e-02\n",
       "    2.26660162e-01  9.93012786e-02]\n",
       "  [-7.52297789e-02 -4.99043763e-02  2.65258700e-01  8.61296356e-02\n",
       "   -1.88572615e-01 -1.30415380e-01  1.82794362e-01  2.03411132e-01\n",
       "    1.78703249e-01  7.17234612e-03]\n",
       "  [-1.08648106e-01 -1.29970908e-01  1.14284992e-01 -1.32421017e-01\n",
       "   -8.48268420e-02  2.39276677e-01  1.27584398e-01 -1.96026087e-01\n",
       "   -1.87178984e-01 -7.36552924e-02]\n",
       "  [-2.39831582e-01  2.23503083e-01 -2.59140730e-01  2.18712240e-01\n",
       "    1.03326440e-02  2.44396180e-01 -2.89652050e-02 -2.21144766e-01\n",
       "   -1.73642635e-02 -1.32037923e-01]\n",
       "  [ 2.27057546e-01 -4.73256111e-02 -2.57810652e-02  1.79928422e-01\n",
       "    2.38614649e-01 -1.55659929e-01  9.74806845e-02 -1.86190039e-01\n",
       "    1.32299632e-01  1.59311891e-02]\n",
       "  [ 2.61802107e-01 -2.22794205e-01  4.90206480e-03 -9.85149145e-02\n",
       "   -2.51478612e-01  1.90176964e-02 -1.97774976e-01 -2.37369582e-01\n",
       "   -1.84770018e-01  1.50110871e-01]\n",
       "  [-1.71273261e-01  2.11356521e-01 -1.87310085e-01  1.46098733e-02\n",
       "   -2.18445837e-01  2.44926065e-01  6.40498698e-02  1.34939790e-01\n",
       "    2.05467045e-02 -2.49517992e-01]\n",
       "  [ 2.69041270e-01  1.47504628e-01  6.16363585e-02 -2.49895796e-01\n",
       "   -2.47752935e-01  1.23453289e-01 -2.38042772e-02  2.12858021e-02\n",
       "   -2.42340624e-01 -2.28767291e-01]\n",
       "  [-1.69920564e-01  2.82575101e-01  4.27054167e-02  3.09095681e-02\n",
       "   -2.31632814e-01 -2.59676427e-01 -1.82018742e-01  1.97407097e-01\n",
       "   -1.35391369e-01  7.70387352e-02]\n",
       "  [-6.59621805e-02  2.23765820e-01 -1.32736906e-01 -2.76855707e-01\n",
       "   -2.17174947e-01 -4.20577526e-02  1.66857243e-03 -1.35399118e-01\n",
       "   -7.65665174e-02  2.46114999e-01]\n",
       "  [-1.08280823e-01  2.79929549e-01 -6.68434352e-02  7.23236501e-02\n",
       "   -2.15769589e-01 -1.36064827e-01 -1.35657355e-01 -2.31727660e-02\n",
       "    5.23005724e-02 -9.71010625e-02]\n",
       "  [-2.35360399e-01  2.21745819e-01  1.08488142e-01  7.74779916e-02\n",
       "    1.52625829e-01  2.51589090e-01 -1.88139677e-02  1.38019234e-01\n",
       "    8.09524059e-02  8.15177262e-02]\n",
       "  [ 3.47968042e-02  2.35441238e-01 -2.31985629e-01  4.97502685e-02\n",
       "    2.58390635e-01  1.02785230e-03 -3.67499143e-02 -1.08037710e-01\n",
       "    6.68973327e-02 -2.74355739e-01]\n",
       "  [-1.15372717e-01  8.01131129e-03  7.35498667e-02 -4.17948812e-02\n",
       "    1.54507995e-01 -4.52390313e-02  3.96209359e-02 -8.37687999e-02\n",
       "    2.55223513e-02  1.51641905e-01]\n",
       "  [-5.14372438e-02  5.64603508e-02  2.60360032e-01 -1.69603825e-02\n",
       "    1.86319649e-02  2.52866894e-01  1.69901490e-01 -2.19339132e-01\n",
       "   -1.53607503e-01  2.29541063e-02]\n",
       "  [ 2.04899669e-01  3.13919783e-02  2.76028216e-02  1.09273016e-01\n",
       "    2.08249688e-02 -1.65101200e-01 -1.24394566e-01 -1.18245110e-01\n",
       "    1.60671026e-01 -1.32788375e-01]\n",
       "  [-2.26930961e-01  8.08219910e-02  1.81332231e-03  9.02269483e-02\n",
       "   -6.48200512e-05 -2.13629991e-01 -2.51286089e-01  1.05080813e-01\n",
       "    1.81733072e-02  2.52929360e-01]\n",
       "  [ 2.21989244e-01  1.34282529e-01 -2.07092479e-01 -2.05479234e-01\n",
       "   -2.57755369e-01 -2.08206207e-01  7.70398974e-03  1.08940840e-01\n",
       "    1.31634772e-02 -2.66457468e-01]\n",
       "  [ 2.32767969e-01 -4.33896035e-02 -9.04663205e-02 -3.87084484e-03\n",
       "    4.29188609e-02 -1.83399618e-02  9.91853774e-02  1.58345699e-03\n",
       "   -9.62281227e-03  2.30106384e-01]\n",
       "  [-2.72465438e-01  2.56472975e-01  9.29142833e-02  2.27857262e-01\n",
       "   -2.78514028e-01 -5.40577620e-02 -2.80975550e-01  3.56776714e-02\n",
       "   -9.88491327e-02  2.71849602e-01]\n",
       "  [ 7.44660795e-02 -5.99247366e-02 -2.39953905e-01  7.61280060e-02\n",
       "   -2.23717153e-01  1.96158350e-01  1.65331334e-01 -1.65688977e-01\n",
       "    5.64409494e-02  2.70890325e-01]\n",
       "  [ 2.30884284e-01  2.06572115e-02 -1.14334092e-01 -2.18070000e-01\n",
       "   -6.79942220e-02 -5.99919409e-02  2.57854015e-01 -1.71401232e-01\n",
       "   -7.44849741e-02  3.37627232e-02]\n",
       "  [ 2.15831608e-01  2.58213013e-01  3.08474302e-02  2.02965289e-01\n",
       "   -4.95940447e-02  2.79040009e-01  2.55699128e-01  2.14092314e-01\n",
       "    1.91929042e-02 -1.76278651e-01]\n",
       "  [-8.18655342e-02 -9.85259116e-02 -4.77051735e-02  1.38790041e-01\n",
       "   -1.54301256e-01  5.74561357e-02  1.10364348e-01  2.04819083e-01\n",
       "    1.53234869e-01  1.32593602e-01]\n",
       "  [-4.21566069e-02 -2.06875369e-01  2.39644200e-01 -3.24236751e-02\n",
       "    2.33893484e-01 -1.11040771e-02  1.41976327e-01  1.68915004e-01\n",
       "    1.02637619e-01 -9.96040553e-02]\n",
       "  [-1.39559418e-01  1.80538893e-02  2.73355395e-01 -1.52075931e-01\n",
       "    2.56752372e-02 -4.89061922e-02 -1.11227334e-02 -1.02210462e-01\n",
       "    4.21851873e-04 -6.20239228e-02]\n",
       "  [-2.12913483e-01 -2.71626413e-01  2.50410050e-01  1.10092103e-01\n",
       "    6.19379878e-02 -1.43516466e-01 -2.48686552e-01  1.35172099e-01\n",
       "    1.40330791e-01 -1.60384461e-01]\n",
       "  [ 1.01361245e-01  5.07735014e-02  1.92052335e-01 -2.84487188e-01\n",
       "   -1.27806947e-01 -1.16735727e-01 -2.84468234e-01  1.09440655e-01\n",
       "    1.62450135e-01  2.80633062e-01]\n",
       "  [ 1.10197812e-01 -8.43046457e-02  2.05054283e-02  8.68373811e-02\n",
       "   -6.62568063e-02  3.16308141e-02 -6.96433187e-02  1.79107457e-01\n",
       "    3.29738557e-02  8.00477266e-02]\n",
       "  [-1.93384856e-01  1.70318812e-01  1.43215865e-01 -2.16046870e-02\n",
       "   -3.43422294e-02 -2.77042240e-01  9.23693776e-02  4.08244133e-03\n",
       "   -3.14050615e-02 -2.73455054e-01]\n",
       "  [ 2.80455977e-01 -7.69859254e-02 -2.33401537e-01 -4.89038229e-02\n",
       "    1.85772121e-01  2.14026600e-01  2.69343227e-01  4.02223766e-02\n",
       "   -1.87272877e-01 -2.67162621e-01]\n",
       "  [ 1.61882699e-01 -2.46450081e-01 -1.50748491e-01 -4.51107174e-02\n",
       "   -2.19382703e-01 -1.98085308e-01  1.10644579e-01  2.75328845e-01\n",
       "    2.51413673e-01  1.85479730e-01]\n",
       "  [-9.75672454e-02  1.21388167e-01 -1.52923584e-01  2.11215913e-02\n",
       "    1.88201070e-01  9.56278741e-02  1.19405955e-01  1.34585261e-01\n",
       "   -2.37541616e-01 -1.48957238e-01]\n",
       "  [-2.69949615e-01  2.06468701e-01 -1.00810379e-01 -2.69252330e-01\n",
       "    4.30020988e-02 -1.33594692e-01  5.26160598e-02  2.39616632e-02\n",
       "   -2.24190146e-01 -1.74369603e-01]\n",
       "  [-1.90245330e-01 -2.79841185e-01  1.87041849e-01  4.09591794e-02\n",
       "    2.71965116e-01  3.86598408e-02 -1.35727286e-01  1.62622094e-01\n",
       "    1.28913671e-01 -2.50896215e-02]\n",
       "  [-1.06898129e-01  8.52020085e-02  2.19971508e-01 -9.49714482e-02\n",
       "   -2.10550681e-01 -2.73464561e-01 -1.60652012e-01  1.22605085e-01\n",
       "    2.19704181e-01  2.70529121e-01]\n",
       "  [-2.08989084e-02  1.20974928e-01  2.64254779e-01  2.42970496e-01\n",
       "   -3.75383049e-02  1.62038207e-02  2.69475967e-01  1.54271185e-01\n",
       "   -2.74397582e-01 -9.98994410e-02]\n",
       "  [ 2.81987339e-01 -1.28948703e-01 -2.65284687e-01  7.16131926e-02\n",
       "   -9.76678580e-02 -1.66308805e-01  1.65457875e-01  5.06681800e-02\n",
       "    2.83828169e-01 -9.04450119e-02]\n",
       "  [ 2.22962588e-01  2.60974199e-01  2.11661816e-01  7.16364384e-03\n",
       "    1.88809901e-01 -1.54979616e-01  2.62773722e-01 -1.86930656e-01\n",
       "   -9.10985768e-02  2.18027502e-01]\n",
       "  [ 1.21667981e-02 -8.07397217e-02  5.14306426e-02  1.90257132e-02\n",
       "    2.53670812e-02  2.81538218e-01  4.30993736e-02  2.12289989e-01\n",
       "    2.45794982e-01  9.43047106e-02]\n",
       "  [ 8.25694203e-03  2.35933512e-01 -1.11036167e-01 -1.54935345e-01\n",
       "    1.23169035e-01 -8.41652751e-02  1.13526613e-01  2.25218862e-01\n",
       "    2.66274184e-01  2.15852886e-01]\n",
       "  [-7.83598721e-02  2.03485727e-01  1.12628639e-01  1.00624293e-01\n",
       "   -1.97980478e-01  9.13095772e-02 -1.87649801e-01 -2.34695435e-01\n",
       "   -2.37900272e-01 -4.56184596e-02]\n",
       "  [-1.29951090e-01  1.99482262e-01 -7.89595991e-02 -2.23999783e-01\n",
       "   -1.02951199e-01  2.20852792e-02  3.64494324e-02 -1.28629014e-01\n",
       "   -5.88490963e-02  3.04546356e-02]\n",
       "  [-9.50740278e-02 -4.90673035e-02  1.02902591e-01  9.19604897e-02\n",
       "    2.82918781e-01  1.93641067e-01 -2.73018003e-01 -1.36374474e-01\n",
       "    2.80763656e-01 -1.74009264e-01]\n",
       "  [-1.10083520e-02  4.83541191e-02 -2.48475760e-01  3.15189958e-02\n",
       "   -1.67317227e-01 -8.85473043e-02 -1.44522458e-01  1.55183136e-01\n",
       "    5.28755486e-02  1.50796950e-01]\n",
       "  [ 1.60322756e-01 -1.10212535e-01  2.37078220e-01 -2.51452923e-02\n",
       "   -1.05013385e-01 -9.15156901e-02  1.04203522e-02  1.19184077e-01\n",
       "   -2.74711818e-01 -1.32394478e-01]\n",
       "  [ 1.87290132e-01  1.36023819e-01 -2.37324774e-01 -2.17552960e-01\n",
       "    3.25360298e-02  2.23062187e-01 -2.84575552e-01 -8.14538449e-02\n",
       "   -5.10911345e-02 -1.56978056e-01]\n",
       "  [ 1.91256821e-01  2.50872761e-01  5.31855226e-02  1.02162242e-01\n",
       "    1.06039405e-01  5.87780774e-02  6.54374659e-02 -1.22307792e-01\n",
       "   -2.54478157e-01 -2.46589452e-01]\n",
       "  [-2.58092791e-01  2.55379647e-01 -3.11931968e-02  2.66100168e-02\n",
       "   -1.70725524e-01 -2.76934117e-01 -1.64993376e-01  2.85328329e-02\n",
       "    2.91363001e-02 -1.92873254e-01]\n",
       "  [-2.07447886e-01 -1.84419155e-01 -1.62581965e-01  1.71619028e-01\n",
       "   -2.81482548e-01 -1.66618168e-01  1.70380801e-01 -4.88749743e-02\n",
       "    2.37343282e-01 -9.46101397e-02]\n",
       "  [-6.00859523e-03 -1.94406047e-01  1.21587962e-01 -2.54364461e-01\n",
       "   -3.09425592e-03  1.51030570e-01 -2.00133026e-01  1.64141655e-02\n",
       "   -5.10003120e-02 -2.70699024e-01]\n",
       "  [ 2.60136992e-01 -1.87254280e-01  1.35042012e-01 -1.96655691e-02\n",
       "   -9.14543867e-02 -1.91006660e-02 -1.93938836e-01 -2.50479311e-01\n",
       "   -1.20547086e-01 -2.34001875e-01]\n",
       "  [ 2.03787506e-01  2.00064480e-01  1.81767136e-01 -9.59062129e-02\n",
       "   -2.28151873e-01  2.04871953e-01 -1.89068466e-01 -2.48130560e-02\n",
       "   -5.92554808e-02 -3.32469642e-02]\n",
       "  [-1.75677493e-01 -1.14206865e-01 -9.61761326e-02  2.53668427e-03\n",
       "    1.03545785e-02 -3.38110030e-02 -5.99702150e-02  2.22754270e-01\n",
       "   -8.72448534e-02 -4.79212701e-02]\n",
       "  [-2.66077697e-01 -4.29774523e-02 -9.40397382e-02 -2.66430110e-01\n",
       "    8.98994505e-02 -8.92141759e-02 -2.01278180e-01  1.15446180e-01\n",
       "   -1.37923360e-01  1.05682313e-01]\n",
       "  [ 8.37731957e-02  1.98937982e-01  7.20384717e-03 -2.60377526e-01\n",
       "   -2.77803779e-01  1.83543801e-01 -2.74955332e-02  6.36312068e-02\n",
       "   -2.34407172e-01  1.30522907e-01]]>,\n",
       " <Variable path=sequential_1/dense_3/bias, shape=(10,), dtype=float32, value=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Builds the model. Now the model will expect samples of shape\n",
    "# (3,). The None in the input shape signals that the batch size\n",
    "# could be anything.\n",
    "model.build(input_shape=(None, 3))\n",
    "# Now you can retrieve the model's weights.\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구축이 완료되면 summary() 메서드를 통해 모델의 내용을 표시할 수 있으며, 이는 디버깅에 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape             </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m256\u001b[0m │\n",
       "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)               │           \u001b[38;5;34m650\u001b[0m │\n",
       "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary(line_length=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보시다시피, 모델 이름이 sequential_1로 지정되었습니다. 케라스에서는 모델, 레이어 등 모든 것에 이름을 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_example_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"my_example_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape             </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ my_first_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
       "│ my_last_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ my_first_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m256\u001b[0m │\n",
       "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
       "│ my_last_layer (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)               │           \u001b[38;5;34m650\u001b[0m │\n",
       "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary(line_length=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential 모델을 점진적으로 구축할 때, 각 레이어를 추가한 후 현재 모델의 모습을 요약해서 출력하는 것이 유용합니다. 하지만 모델 구축이 완료되기 전까지는 요약 출력을 할 수 없습니다! 사실, Sequential 모델을 동적으로 구축하는 방법이 있습니다. 바로 모델 입력의 형태를 미리 선언하는 것입니다. Input 클래스를 통해 이를 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# Use an Input to declare the shape of the inputs. Note that the shape\n",
    "# argument must be the shape of each sample, not the shape of one\n",
    "# batch.\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 summary() 함수를 사용하여 레이어를 추가함에 따라 모델의 출력 형태가 어떻게 변하는지 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape             </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m256\u001b[0m │\n",
       "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary(line_length=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape             </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m256\u001b[0m │\n",
       "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)               │           \u001b[38;5;34m650\u001b[0m │\n",
       "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary(line_length=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이는 8장에서 배우게 될 컨볼루션 레이어처럼 입력값을 복잡한 방식으로 변환하는 레이어를 다룰 때 흔히 사용하는 디버깅 워크플로입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The Functional API\n",
    "\n",
    "Sequential 모델은 사용하기 쉽지만 적용 범위가 매우 제한적입니다. 단일 입력과 단일 출력을 가진 모델만 표현할 수 있으며, 레이어를 순차적으로 적용하는 방식만 가능합니다. 하지만 실제로는 여러 입력(예: 이미지와 메타데이터), 여러 출력(데이터에 대해 예측하고자 하는 다양한 값), 또는 비선형 토폴로지를 가진 모델을 흔히 접하게 됩니다.\r\n",
    "\r\n",
    "이러한 경우에는 Functional API를 사용하여 모델을 구축합니다. 대부분의 Keras 모델은 이 Functional API를 사용합니다. 마치 레고 블록을 가지고 노는 것처럼 재미있고 강력한 기능을 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### A simple example\n",
    "\n",
    "간단한 것부터 시작해 보겠습니다. 이전 섹션에서 사용했던 2계층 스택입니다. 해당 스택의 함수형 API 버전은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"my_functional_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단계별로 살펴보겠습니다. 먼저 Input 객체를 선언했습니다(다른 모든 객체와 마찬가지로 Input 객체에도 이름을 지정할 수 있습니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 입력 객체는 모델이 처리할 데이터의 형태와 데이터 유형에 대한 정보를 담고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The model will process batches where each sample has shape (3,).\n",
    "# The number of samples per batch is variable (indicated by the\n",
    "# None batch size).\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float32'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These batches will have dtype float32.\n",
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 이러한 객체를 심볼릭 텐서라고 부릅니다. 심볼릭 텐서 자체는 실제 데이터를 포함하지 않지만, 모델을 사용할 때 모델이 보게 될 실제 데이터 텐서의 명세를 인코딩합니다. 이는 미래의 데이터 텐서를 의미합니다.\r\n",
    "\r\n",
    "다음으로, 레이어를 생성하고 입력에 대해 호출했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 Keras 레이어는 실제 데이터 텐서 또는 기호 텐서 모두에서 호출할 수 있습니다. 후자의 경우, 업데이트된 모양과 데이터 유형 정보를 포함하는 새로운 기호 텐서를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종 결과를 얻은 후, 모델 생성자에서 입력과 출력을 지정하여 모델을 인스턴스화했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"my_functional_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 저희 모델의 요약입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_functional_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"my_functional_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                      </span>┃<span style=\"font-weight: bold\"> Output Shape             </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ my_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ my_input (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                │             \u001b[38;5;34m0\u001b[0m │\n",
       "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m256\u001b[0m │\n",
       "├───────────────────────────────────┼──────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)               │           \u001b[38;5;34m650\u001b[0m │\n",
       "└───────────────────────────────────┴──────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">906</span> (3.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m906\u001b[0m (3.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary(line_length=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### Multi-input, multi-output models\n",
    "\n",
    "이 간단한 모델과 달리 대부분의 딥러닝 모델은 리스트 형태가 아니라 그래프 형태를 띕니다. 예를 들어, 여러 개의 입력이나 여러 개의 출력을 가질 수 있습니다. 함수형 API는 바로 이러한 유형의 모델에서 진가를 발휘합니다.\r\n",
    "\r\n",
    "고객 지원 티켓을 우선순위에 따라 순위를 매기고 적절한 부서로 배정하는 시스템을 구축한다고 가정해 보겠습니다. 모델에는 세 가지 입력이 있습니다.\r\n",
    "\r\n",
    "* 티켓 제목(텍스트 입력)\r\n",
    "* 티켓 본문(텍스트 입력)\r\n",
    "* 사용자가 추가한 태그(범주형 입력, 여기서는 멀티핫 인코딩되었다고 가정)\r\n",
    "\r\n",
    "텍스트 입력은 vocabulary_size 크기의 1과 0으로 이루어진 배열로 인코딩할 수 있습니다(텍스트 인코딩 기법에 대한 자세한 내용은 14장을 참조하세요).\r\n",
    "\r\n",
    "모델에는 두 가지 출력도 있습니다.\r\n",
    "\r\n",
    "* 티켓의 우선순위 점수(0에서 1 사이의 스칼라 값, 시그모이드 함수)\r\n",
    "* 티켓을 처리해야 하는 부서(부서 집합에 대한 소프트맥스 함수)\r\n",
    "\r\n",
    "함수형 API를 사용하면 몇 줄의 코드로 이 모델을 구축할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\", name=\"dense_features\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\"\n",
    ")(features)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수형 API는 레고처럼 간단하면서도 매우 유연한 방식으로 이러한 계층 구조의 임의 그래프를 정의할 수 있는 방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### Training a multi-input, multi-output model\n",
    "\n",
    "Sequential 모델을 학습시키는 것과 거의 같은 방식으로, 입력 및 출력 데이터 목록을 사용하여 fit() 메서드를 호출함으로써 모델을 학습시킬 수 있습니다. 이러한 데이터 목록은 Model() 생성자에 전달한 입력 순서와 동일해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - department_accuracy: 0.2492 - department_loss: 3.1815 - loss: 3.4182 - priority_loss: 0.2368 - priority_mean_absolute_error: 0.4041\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - department_accuracy: 0.2672 - department_loss: 1.3567 - loss: 1.4378 - priority_loss: 0.0811 - priority_mean_absolute_error: 0.2468\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, num_departments, size=(num_samples, 1))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=[\"mean_squared_error\", \"sparse_categorical_crossentropy\"],\n",
    "    metrics=[[\"mean_absolute_error\"], [\"accuracy\"]],\n",
    ")\n",
    "model.fit(\n",
    "    [title_data, text_body_data, tags_data],\n",
    "    [priority_data, department_data],\n",
    "    epochs=1,\n",
    ")\n",
    "model.evaluate(\n",
    "    [title_data, text_body_data, tags_data], [priority_data, department_data]\n",
    ")\n",
    "priority_preds, department_preds = model.predict(\n",
    "    [title_data, text_body_data, tags_data]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 순서에 의존하고 싶지 않은 경우(예: 입력이나 출력이 많은 경우) 입력 객체와 출력 레이어에 지정한 이름을 사용하여 딕셔너리를 통해 데이터를 전달할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - department_accuracy: 0.2594 - department_loss: 1.3875 - loss: 1.4687 - priority_loss: 0.0812 - priority_mean_absolute_error: 0.2451\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - department_accuracy: 0.2562 - department_loss: 1.3843 - loss: 1.4654 - priority_loss: 0.0811 - priority_mean_absolute_error: 0.2470\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\n",
    "        \"priority\": \"mean_squared_error\",\n",
    "        \"department\": \"sparse_categorical_crossentropy\",\n",
    "    },\n",
    "    metrics={\n",
    "        \"priority\": [\"mean_absolute_error\"],\n",
    "        \"department\": [\"accuracy\"],\n",
    "    },\n",
    ")\n",
    "model.fit(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "    {\"priority\": priority_data, \"department\": department_data},\n",
    "    epochs=1,\n",
    ")\n",
    "model.evaluate(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "    {\"priority\": priority_data, \"department\": department_data},\n",
    ")\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### The power of the Functional API: Access to layer connectivity\n",
    "\n",
    "함수형 모델은 명시적인 그래프 데이터 구조입니다. 이를 통해 레이어 간의 연결 방식을 살펴보고 이전 그래프 노드(레이어 출력)를 새로운 모델의 일부로 재사용할 수 있습니다. 또한 대부분의 연구자들이 심층 신경망을 생각할 때 떠올리는 \"레이어 그래프\"라는 \"정신적 모델\"과도 잘 맞아떨어집니다.\r\n",
    "\r\n",
    "이러한 특징은 모델 시각화와 특징 추출이라는 두 가지 중요한 활용 사례를 가능하게 합니다. 이제 자세히 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "###### Plotting layer connectivity\n",
    "\n",
    "방금 정의한 모델의 연결성(모델의 토폴로지)을 시각화해 보겠습니다. 그림 7.2에서처럼 plot_model() 유틸리티를 사용하여 함수형 모델을 그래프로 나타낼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 그래프에는 모델의 각 레이어의 입력 및 출력 형태와 레이어 이름(레이어 유형뿐 아니라)도 추가할 수 있으며, 이는 디버깅 중에 유용할 수 있습니다(그림 7.3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(\n",
    "    model,\n",
    "    \"ticket_classifier_with_shape_info.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서 형태의 None은 배치 크기를 나타냅니다. 이 모델은 임의의 크기의 배치를 허용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "###### Feature extraction with a Functional model\n",
    "\n",
    "레이어 연결에 접근할 수 있다는 것은 그래프에서 개별 노드(레이어 호출)를 검사하고 재사용할 수 있음을 의미합니다. 모델 속성 `model.layers`는 모델을 구성하는 레이어 목록을 제공하며, 각 레이어에 대해 `layer.input`과 `layer.output`을 쿼리할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<InputLayer name=title, built=True>,\n",
       " <InputLayer name=text_body, built=True>,\n",
       " <InputLayer name=tags, built=True>,\n",
       " <Concatenate name=concatenate, built=True>,\n",
       " <Dense name=dense_features, built=True>,\n",
       " <Dense name=priority, built=True>,\n",
       " <Dense name=department, built=True>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor shape=(None, 10000), dtype=float32, sparse=False, ragged=False, name=title>,\n",
       " <KerasTensor shape=(None, 10000), dtype=float32, sparse=False, ragged=False, name=text_body>,\n",
       " <KerasTensor shape=(None, 100), dtype=float32, sparse=False, ragged=False, name=tags>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 20100), dtype=float32, sparse=False, ragged=False, name=keras_tensor_14>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 통해 특징 추출, 즉 다른 모델의 중간 특징을 재사용하는 모델을 만들 수 있습니다.\r\n",
    "\r\n",
    "예를 들어, 이전에 정의한 모델에 또 다른 출력을 추가하고 싶다고 가정해 보겠습니다. 특정 이슈 티켓이 해결되는 데 걸리는 시간을 예측하는 기능, 즉 난이도 등급을 추가하고 싶다고 해봅시다. 이 경우 \"빠름\", \"중간\", \"어려움\"의 세 가지 범주로 분류하는 레이어를 사용할 수 있습니다. 처음부터 모델을 다시 만들고 학습시킬 필요가 없습니다! 이전 모델의 중간 특징에 접근할 수 있으므로 이를 활용하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags], outputs=[priority, department, difficulty]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림 7.4에서 보는 것처럼 새로운 모델을 그래프로 나타내 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(\n",
    "    new_model,\n",
    "    \"updated_ticket_classifier.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Subclassing the Model class\n",
    "\n",
    "마지막으로 알아야 할 모델 구축 패턴은 가장 고급 패턴인 모델 서브클래싱입니다. 3장에서 Layer 클래스를 서브클래싱하여 사용자 정의 레이어를 만드는 방법을 이미 배웠습니다. Model을 서브클래싱하는 방법도 이와 매우 유사합니다.\r\n",
    "\r\n",
    "* __init__ 메서드에서 모델이 사용할 레이어를 정의합니다.\r\n",
    "\r\n",
    "* call 메서드에서 이전에 생성한 레이어를 재사용하여 모델의 순방향 전달을 정의합니다.\r\n",
    "\r\n",
    "* 서브클래스의 인스턴스를 생성하고 데이터를 호출하여 가중치를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### Rewriting our previous example as a subclassed model\n",
    "\n",
    "간단한 예제를 살펴보겠습니다. Model 서브클래스를 사용하여 고객 지원 티켓 관리 모델을 다시 구현해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 정의했으면 인스턴스를 생성할 수 있습니다. 레이어 하위 클래스와 마찬가지로, 모델은 데이터를 사용하여 처음 호출할 때만 가중치를 생성한다는 점에 유의하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지는 3장에서 이미 다뤘던 레이어 서브클래싱 워크플로와 매우 유사해 보입니다. 그렇다면 레이어 서브클래스와 모델 서브클래스의 차이점은 무엇일까요? 간단히 말해, 레이어는 모델을 만드는 데 사용하는 빌딩 블록이고, 모델은 실제로 학습시키고 추론을 위해 내보내는 등의 작업을 수행하는 최상위 객체입니다. 즉, 모델에는 `fit()`, `evaluate()`, `predict()` 메서드가 있지만 레이어에는 이러한 메서드가 없습니다. 그 외에는 두 클래스가 사실상 동일합니다(또 다른 차이점은 모델을 디스크의 파일로 저장할 수 있다는 점인데, 이는 몇 섹션 뒤에 자세히 다루겠습니다).\r\n",
    "\r\n",
    "모델 서브클래스는 순차 모델이나 함수형 모델처럼 컴파일하고 학습시킬 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.2492 - loss: 2.1047 - mean_absolute_error: 0.2732 - mean_squared_error_loss: 0.1059 - sparse_categorical_crossentropy_loss: 1.9988\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2469 - loss: 1.4619 - mean_absolute_error: 0.2479 - mean_squared_error_loss: 0.0820 - sparse_categorical_crossentropy_loss: 1.3799\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    # The structure of what you pass as the loss and metrics must match\n",
    "    # exactly what gets returned by call() — since we returned a list\n",
    "    # of two elements, so should loss and metrics be lists of two\n",
    "    # elements.\n",
    "    loss=[\"mean_squared_error\", \"sparse_categorical_crossentropy\"],\n",
    "    metrics=[[\"mean_absolute_error\"], [\"accuracy\"]],\n",
    ")\n",
    "model.fit(\n",
    "    # The structure of the input data must match exactly what is\n",
    "    # expected by the call() method, and the structure of the target\n",
    "    # data must match exactly what gets returned by the call() method.\n",
    "    # Here, the input data must be a dict with three keys (title,\n",
    "    # text_body, and tags) and the target data must be a list of two\n",
    "    # elements.\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "    [priority_data, department_data],\n",
    "    epochs=1,\n",
    ")\n",
    "model.evaluate(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "    [priority_data, department_data],\n",
    ")\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 서브클래싱 워크플로는 모델을 구축하는 가장 유연한 방법입니다. 이를 통해 레이어의 방향성 비순환 그래프(DAG)로 표현할 수 없는 모델도 구축할 수 있습니다. 예를 들어, `call()` 메서드가 `for` 루프 안에서 레이어를 사용하거나 재귀적으로 호출하는 모델을 상상해 보세요. 무엇이든 가능합니다. 모든 것은 당신의 손에 달려 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### Beware: What subclassed models don't support\n",
    "\n",
    "이러한 자유에는 대가가 따릅니다. 서브클래싱 모델을 사용하면 모델 로직의 더 많은 부분을 직접 구현해야 하므로 잠재적인 오류 발생 가능성이 훨씬 커집니다. 결과적으로 디버깅 작업량이 증가합니다. 레고 블록을 조립하는 것이 아니라 새로운 파이썬 객체를 개발하는 것과 같습니다.\r\n",
    "\r\n",
    "함수형 모델과 서브클래싱 모델은 본질적으로도 상당히 다릅니다. 함수형 모델은 명시적인 데이터 구조, 즉 레이어 그래프로 구성되어 있어 보고, 검사하고, 수정할 수 있습니다. 반면 서브클래싱 모델은 바이트코드, 즉 원시 코드를 포함하는 `call()` 메서드를 가진 파이썬 클래스입니다. 서브클래싱 워크플로의 유연성은 바로 이 부분에서 비롯됩니다. 원하는 기능을 자유롭게 구현할 수 있지만, 동시에 새로운 제약 조건도 발생합니다.\r\n",
    "\r\n",
    "예를 들어, 레이어 간 연결 방식은 `call()` 메서드 본문 내에 숨겨져 있기 때문에 해당 정보에 접근할 수 없습니다. `summary()`를 호출해도 레이어 연결 정보가 표시되지 않으며, `plot_model()`을 통해 모델 토폴로지를 시각화할 수도 없습니다. 마찬가지로, 서브클래스화된 모델의 경우, 특징 추출을 위해 레이어 그래프의 노드에 접근할 수 없습니다. 그래프 자체가 존재하지 않기 때문입니다. 모델이 인스턴스화되면, 순방향 전달 과정은 완전히 블랙박스가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Mixing and matching different components\n",
    "\n",
    "무엇보다 중요한 것은, 시퀀셜 모델, 함수형 API, 모델 서브클래싱과 같은 패턴 중 하나를 선택한다고 해서 다른 패턴을 사용할 수 없게 되는 것은 아니라는 점입니다. Keras API의 모든 모델은 시퀀셜 모델이든, 함수형 모델이든, 처음부터 직접 작성한 서브클래싱 모델이든 관계없이 서로 원활하게 상호 운용될 수 있습니다. 이들은 모두 동일한 워크플로우의 범주에 속합니다. 예를 들어, 함수형 모델에서 서브클래싱된 레이어나 모델을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Classifier(keras.Model):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반대로, 함수형 모델을 하위 클래스 레이어 또는 모델의 일부로 사용할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Remember: Use the right tool for the job\n",
    "\n",
    "\n",
    "지금까지 가장 간단한 순차 모델 워크플로부터 가장 고급 워크플로인 모델 서브클래싱까지, 케라스 모델을 구축하는 다양한 워크플로에 대해 알아보았습니다. 어떤 워크플로를 언제 사용해야 할까요? 각 워크플로에는 장단점이 있으므로, 주어진 작업에 가장 적합한 워크플로를 선택하십시오.\n",
    "\n",
    "일반적으로 함수형 API는 사용 편의성과 유연성 사이에서 훌륭한 균형을 제공합니다. 또한 레이어 연결에 직접 접근할 수 있어 모델 플로팅이나 특징 추출과 같은 사용 사례에 매우 유용합니다. 모델을 레이어의 방향성 비순환 그래프(DAG)로 표현할 수 있다면 함수형 API를 사용하는 것이 좋습니다.\n",
    "\n",
    "이 책의 모든 예제에서는 함수형 API를 사용합니다. 우리가 다룰 모든 모델은 레이어 그래프로 표현할 수 있기 때문입니다. 하지만 서브클래싱된 레이어도 자주 사용할 것입니다. 일반적으로 서브클래싱된 레이어를 포함하는 함수형 모델을 사용하면 함수형 API의 장점을 유지하면서 개발 유연성을 극대화할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using built-in training and evaluation loops\n",
    "\n",
    "복잡성의 점진적 공개 원칙, 즉 아주 쉬운 워크플로우부터 임의로 유연한 워크플로우까지 단계적으로 접근할 수 있도록 하는 원칙은 모델 학습에도 적용됩니다. Keras는 모델 학습을 위한 다양한 워크플로우를 제공합니다. 데이터에 대해 `fit()`을 호출하는 것처럼 간단한 방법부터 새로운 학습 알고리즘을 처음부터 작성하는 것처럼 고급 방법까지 다양하게 활용할 수 있습니다.\r\n",
    "\r\n",
    "이미 `compile()`, `fit()`, `evaluate()`, `predict()`로 이어지는 워크플로우에 익숙하실 겁니다. 다시 한번 말씀드리자면, 다음 목록과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2902 - val_accuracy: 0.9588 - val_loss: 0.1428\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9554 - loss: 0.1461 - val_accuracy: 0.9648 - val_loss: 0.1148\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9636 - loss: 0.1182 - val_accuracy: 0.9755 - val_loss: 0.0879\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9743 - loss: 0.0829\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=3,\n",
    "    validation_data=(val_images, val_labels),\n",
    ")\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 간단한 워크플로를 사용자 지정하는 방법은 두 가지가 있습니다.\r\n",
    "\r\n",
    "* 사용자 지정 메트릭을 직접 제공하는 방법\r\n",
    "* fit() 메서드에 콜백을 전달하여 학습 중 특정 시점에 수행할 작업을 예약하는 방법\r\n",
    "\r\n",
    "이러한 방법들을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Writing your own metrics\n",
    "\n",
    "메트릭은 모델 성능을 측정하는 데 핵심적인 요소입니다. 특히, 훈련 데이터에서의 성능과 테스트 데이터에서의 성능 차이를 측정하는 데 유용합니다. 분류 및 회귀에 일반적으로 사용되는 메트릭은 이미 `keras.metrics` 모듈에 내장되어 있으므로 대부분의 경우 이를 사용하게 됩니다. 하지만 일반적이지 않은 작업을 수행해야 하는 경우에는 자체 메트릭을 작성할 수 있어야 합니다. 방법은 간단합니다!\r\n",
    "\r\n",
    "Keras 메트릭은 `keras.metrics.Metric` 클래스의 하위 클래스입니다. 레이어와 마찬가지로 메트릭은 Keras 변수에 저장된 내부 상태를 가집니다. 레이어와 달리 이러한 변수는 역전파를 통해 업데이트되지 않으므로 상태 업데이트 로직을 직접 작성해야 합니다. 이 로직은 `update_state()` 메서드에서 구현됩니다. 예를 들어, 다음은 평균 제곱근 오차(RMSE)를 측정하는 간단한 사용자 지정 메트릭입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from keras import ops\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "    # Defines the state variables in the constructor. Like for layers,\n",
    "    # you have access to the add_weight() method.\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\"\n",
    "        )\n",
    "    # Implements the state update logic in update_state(). The y_true\n",
    "    # argument is the targets (or labels) for one batch, while y_pred\n",
    "    # represents the corresponding predictions from the model. To match\n",
    "    # our MNIST model, we expect categorical predictions and integer\n",
    "    # labels. You can ignore the sample_weight argument; we won't use\n",
    "    # it here.\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = ops.one_hot(y_true, num_classes=ops.shape(y_pred)[1])\n",
    "        mse = ops.sum(ops.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = ops.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return ops.sqrt(self.mse_sum / self.total_samples)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자 지정 측정항목은 내장 측정항목처럼 사용할 수 있습니다. 이제 우리가 만든 측정항목을 시험해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2925 - rmse: 0.3639 - val_accuracy: 0.9552 - val_loss: 0.1471 - val_rmse: 0.2603\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9546 - loss: 0.1498 - rmse: 0.2636 - val_accuracy: 0.9721 - val_loss: 0.0962 - val_rmse: 0.2081\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.1159 - rmse: 0.2348 - val_accuracy: 0.9726 - val_loss: 0.0897 - val_rmse: 0.2043\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9724 - loss: 0.0891 - rmse: 0.2036\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\", RootMeanSquaredError()],\n",
    ")\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=3,\n",
    "    validation_data=(val_images, val_labels),\n",
    ")\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 `fit()` 진행률 표시줄에 모델의 RMSE가 표시되는 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Using callbacks\n",
    "\n",
    "`model.fit()`을 사용하여 대규모 데이터셋으로 수십 에포크 동안 학습을 시작하는 것은 마치 종이비행기를 날리는 것과 같습니다. 처음 추진력을 얻은 후에는 궤적이나 착륙 지점을 제어할 수 없습니다. 잘못된 결과(그리고 낭비되는 종이비행기)를 피하려면 종이비행기 대신 주변 환경을 감지하고 조종사에게 데이터를 전송하며 현재 상태에 따라 자동으로 방향을 결정할 수 있는 드론을 사용하는 것이 더 현명합니다. Keras 콜백 API를 사용하면 `model.fit()` 호출을 종이비행기에서 스스로를 진단하고 동적으로 행동할 수 있는 스마트하고 자율적인 드론으로 변환할 수 있습니다.\r\n",
    "\r\n",
    "콜백은 `fit()` 호출 시 모델에 전달되는 객체(특정 메서드를 구현하는 클래스 인스턴스)이며, 학습 과정 중 모델에서 여러 시점에 호출됩니다. 콜백은 모델의 상태 및 성능에 대한 모든 데이터에 접근할 수 있으며, 학습 중단, 모델 저장, 다른 가중치 세트 로드 또는 모델 상태 변경과 같은 작업을 수행할 수 있습니다.\r\n",
    "\r\n",
    "다음은 콜백을 사용하는 몇 가지 예입니다.\r\n",
    "\r\n",
    "* 모델 체크포인트 — 학습 중 다양한 시점에서 모델의 현재 상태를 저장합니다.\r\n",
    "* 조기 종료 — 검증 손실이 더 이상 개선되지 않을 때 학습을 중단합니다(물론 학습 중에 얻은 최적의 모델을 저장합니다).\r\n",
    "* 학습 중 특정 매개변수의 값을 동적으로 조정합니다 — 예를 들어 옵티마이저의 학습률을 조정할 수 있습니다.\r\n",
    "* 학습 중 학습 및 검증 메트릭을 로깅하거나 모델이 학습한 표현이 업데이트됨에 따라 시각화합니다 — 여러분이 잘 알고 있는 `fit()` 진행률 표시줄은 사실 콜백입니다!\r\n",
    "\r\n",
    "`keras.callbacks` 모듈에는 여러 가지 내장 콜백이 포함되어 있습니다(다음은 전체\n",
    "\n",
    "```\n",
    "keras.callbacks.ModelCheckpoint\r\n",
    "keras.callbacks.EarlyStopping\r\n",
    "keras.callbacks.LearningRateScheduler\r\n",
    "keras.callbacks.ReduceLROnPlateau\r\n",
    "keras.callbacks.CSVLo\n",
    "```\n",
    "\n",
    "두 가지 예시를 통해 사용 방법을 알아보겠습니다. 바로 EarlyStopping과 ModelCheckpoint입니다.gger 목록이 아닙니다)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### The EarlyStopping and ModelCheckpoint callbacks\n",
    "\n",
    "모델을 학습시킬 때, 처음에는 예측할 수 없는 요소들이 많습니다. 특히, 최적의 검증 손실에 도달하는 데 필요한 에포크 수를 정확히 알 수는 없습니다. 지금까지의 예제에서는 과적합이 발생할 때까지 충분한 에포크를 학습시킨 후, 첫 번째 실행을 통해 최적의 에포크 수를 찾아내고, 마지막으로 이 최적의 에포크 수를 사용하여 처음부터 다시 학습을 진행하는 전략을 사용했습니다. 물론 이러한 접근 방식은 비효율적입니다. 훨씬 더 나은 방법은 검증 손실이 더 이상 개선되지 않을 때 학습을 중단하는 것입니다. 이는 EarlyStopping 콜백을 사용하여 구현할 수 있습니다.\r\n",
    "\r\n",
    "EarlyStopping 콜백은 모니터링하는 특정 지표가 일정 에포크 동안 개선되지 않으면 학습을 중단합니다. 예를 들어, 이 콜백을 사용하면 과적합이 발생하기 시작하는 즉시 학습을 중단하여, 더 적은 에포크 수로 모델을 다시 학습시키는 번거로움을 피할 수 있습니다. 이 콜백 함수는 일반적으로 ModelCheckpoint와 함께 사용되며, 이를 통해 학습 중에 모델을 지속적으로 저장할 수 있습니다(선택적으로 현재까지 가장 우수한 모델, 즉 에포크 종료 시점에 가장 좋은 성능을 달성한 모델 버전만 저장할 수도 있습니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9122 - loss: 0.2951 - val_accuracy: 0.9599 - val_loss: 0.1370\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1488 - val_accuracy: 0.9716 - val_loss: 0.1005\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9646 - loss: 0.1166 - val_accuracy: 0.9711 - val_loss: 0.0970\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9686 - loss: 0.0989 - val_accuracy: 0.9766 - val_loss: 0.0801\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9737 - loss: 0.0841 - val_accuracy: 0.9771 - val_loss: 0.0732\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.0746 - val_accuracy: 0.9771 - val_loss: 0.0718\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9778 - loss: 0.0694 - val_accuracy: 0.9789 - val_loss: 0.0770\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9796 - loss: 0.0615 - val_accuracy: 0.9795 - val_loss: 0.0764\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.0580 - val_accuracy: 0.9812 - val_loss: 0.0699\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.0532 - val_accuracy: 0.9810 - val_loss: 0.0749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2713841cb90>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Callbacks are passed to the model via the callbacks argument in\n",
    "# fit(), which takes a list of callbacks. You can pass any number of\n",
    "# callbacks.\n",
    "callbacks_list = [\n",
    "    # Interrupts training when improvement stops\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        # Monitors the model's validation accuracy\n",
    "        monitor=\"accuracy\",\n",
    "        # Interrupts training when accuracy has stopped improving for\n",
    "        # more than one epoch (that is, two epochs)\n",
    "        patience=1,\n",
    "    ),\n",
    "    # Saves the current weights after every epoch\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        # Path to the destination model file\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        # These two arguments mean you won't overwrite the model file\n",
    "        # unless val_loss has improved, which allows you to keep the\n",
    "        # best model seen during training.\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    # You monitor accuracy, so it should be part of the model's\n",
    "    # metrics.\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "# Because the callback will monitor validation loss and validation\n",
    "# accuracy, you need to pass validation_data to the call to fit().\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_data=(val_images, val_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고로, 학습 후에는 언제든지 수동으로 모델을 저장할 수 있습니다. `model.save(\"my_checkpoint_path.keras\")`를 호출하면 됩니다. 저장한 모델을 다시 불러오려면 다음 코드를 사용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Writing your own callbacks\n",
    "\n",
    "학습 중에 내장 콜백으로 처리되지 않는 특정 작업을 수행해야 하는 경우, 사용자 지정 콜백을 작성할 수 있습니다. 콜백은 `keras.callbacks.Callback` 클래스를 상속하여 구현합니다. 그런 다음 학습 중 다양한 시점에서 호출되는 다음과 같은 투명한 이름의 메서드를 원하는 만큼 구현할 수 있습니다.\n",
    "\n",
    "```\n",
    "# Called at the start of every epoch\n",
    "on_epoch_begin(epoch, logs)\n",
    "# Called at the end of every epoch\n",
    "on_epoch_end(epoch, logs)\n",
    "# Called right before processing each batch\n",
    "on_batch_begin(batch, logs)\n",
    "# Called right after processing each batch\n",
    "on_batch_end(batch, logs)\n",
    "# Called at the start of training\n",
    "on_train_begin(logs)\n",
    "# Called at the end of training\n",
    "on_train_end(logs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 메서드들은 모두 `logs`라는 인수를 사용하여 호출됩니다. `logs`는 이전 배치, 에포크 또는 학습 실행에 대한 정보(학습 및 검증 지표 등)를 담은 딕셔너리입니다. `on_epoch_*` 및 `on_batch_*` 메서드는 첫 번째 인수로 에포크 또는 배치 인덱스(정수)를 받습니다.\r\n",
    "\r\n",
    "다음은 학습 중에 배치별 손실 값 목록을 저장하고 각 에포크가 끝날 때 이러한 값을 그래프로 표시하는 간단한 콜백 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(\n",
    "            range(len(self.per_batch_losses)),\n",
    "            self.per_batch_losses,\n",
    "            label=\"Training loss for each batch\",\n",
    "        )\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\", dpi=300)\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한번 시운전해 볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2885 - val_accuracy: 0.9574 - val_loss: 0.1457\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9556 - loss: 0.1470 - val_accuracy: 0.9688 - val_loss: 0.1023\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.1153 - val_accuracy: 0.9729 - val_loss: 0.0864\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9692 - loss: 0.0975 - val_accuracy: 0.9755 - val_loss: 0.0848\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9731 - loss: 0.0838 - val_accuracy: 0.9773 - val_loss: 0.0772\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9762 - loss: 0.0742 - val_accuracy: 0.9785 - val_loss: 0.0742\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9774 - loss: 0.0691 - val_accuracy: 0.9784 - val_loss: 0.0770\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9805 - loss: 0.0615 - val_accuracy: 0.9786 - val_loss: 0.0738\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.0600 - val_accuracy: 0.9791 - val_loss: 0.0747\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.0583 - val_accuracy: 0.9801 - val_loss: 0.0794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2713a1b1a30>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=10,\n",
    "    callbacks=[LossHistory()],\n",
    "    validation_data=(val_images, val_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림 7.5와 같은 그래프를 얻게 됩니다.\n",
    "\n",
    "<img src=\"https://deeplearningwithpython.io/images/ch07/loss_history_callback_example.1e42f6b2.png\" width=\"600\"><p style=\"text-align:center\">Figure 7.5: The output of our custom history-plotting callback</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Monitoring and visualization with TensorBoard\n",
    "\n",
    "훌륭한 연구를 수행하거나 좋은 모델을 개발하려면 실험 중에 모델 내부에서 무슨 일이 일어나고 있는지에 대한 풍부하고 빈번한 피드백이 필요합니다. 실험을 실행하는 목적은 바로 모델의 성능에 대한 정보를 최대한 많이 얻는 것입니다. 발전은 반복적인 과정, 즉 루프입니다. 아이디어에서 시작하여 이를 실험으로 구현하고 아이디어를 검증하거나 반증하려고 시도합니다. 그림 7.6에서처럼 이 실험을 실행하고 생성된 정보를 처리합니다. 이 정보는 다음 아이디어에 영감을 줍니다. 이 루프를 더 많이 반복할수록 아이디어는 더욱 정교해지고 강력해집니다. Keras는 아이디어에서 실험까지 최소한의 시간으로 진행할 수 있도록 도와주고, 빠른 GPU는 실험에서 결과까지 최대한 빠르게 도달할 수 있도록 도와줍니다. 그렇다면 실험 결과를 처리하는 방법은 무엇일까요? 바로 TensorBoard가 필요한 부분입니다.\r\n",
    "<img src=\"https://deeplearningwithpython.io/images/ch07/the_loop_of_progress.df126e89.png\" width=\"600\"><p style=\"text-align:center\">Figure 7.6: The loop of progress</p>\n",
    "\r\n",
    "그림 7.6: 발전의 루프\r\n",
    "TensorBoard는 로컬에서 실행할 수 있는 브라우저 기반 애플리케이션입니다. 학습 중에 모델 내부에서 일어나는 모든 일을 모니터링하는 가장 좋은 방법입니다. TensorBoard를 사용하면 다음과 같은 작업을 수행할 수 있습니\r\n",
    "* 학습 중 메트릭을 시각적으로 모니터링\r\n",
    "* 모델 아키텍처 시각화\r\n",
    "* 활성화 및 기울기 히스토그램 시각화\r\n",
    "* 임베딩을 3D로 탐색\r\n",
    "\r\n",
    "모델의 최종 손실뿐만 아니라 더 많은 정보를 모니터링하면 모델의 동작과 한계를 더 명확하게 파악하고 학습 속도를 높일 수 있습니다.\r\n",
    " 수 있습니다.\r\n",
    "\r\n",
    "Keras 모델과 `fit()` 메서드에서 TensorBoard를 사용하는 가장 쉬운 방법은 `keras.callbacks.TensorBoard` 콜백을 사용하는 것입니다. 가장 간단한 경우, 콜백이 로그를 기록할 위치만 지정하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9136 - loss: 0.2910 - val_accuracy: 0.9596 - val_loss: 0.1456\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9542 - loss: 0.1485 - val_accuracy: 0.9695 - val_loss: 0.1023\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.1146 - val_accuracy: 0.9730 - val_loss: 0.0883\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9694 - loss: 0.0976 - val_accuracy: 0.9754 - val_loss: 0.0781\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9726 - loss: 0.0866 - val_accuracy: 0.9765 - val_loss: 0.0805\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9756 - loss: 0.0750 - val_accuracy: 0.9778 - val_loss: 0.0758\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9777 - loss: 0.0697 - val_accuracy: 0.9793 - val_loss: 0.0733\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9794 - loss: 0.0638 - val_accuracy: 0.9819 - val_loss: 0.0684\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.0573 - val_accuracy: 0.9782 - val_loss: 0.0734\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0557 - val_accuracy: 0.9799 - val_loss: 0.0743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2713c71af60>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=10,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[tensorboard],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 실행이 시작되면 지정된 위치에 로그가 기록됩니다. 로컬 머신에서 Python 스크립트를 실행하는 경우 다음 명령을 사용하여 로컬 TensorBoard 서버를 시작할 수 있습니다(TensorFlow를 pip를 통해 설치했다면 tensorboard 실행 파일이 이미 있어야 합니다. 그렇지 않은 경우 pip install tensorboard 명령을 사용하여 TensorBoard를 수동으로 설치할 수 있습니다)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "명령이 반환하는 URL로 이동하면 TensorBoard 인터페이스에 액세스할 수 있습니다.\r\n",
    "\r\n",
    "스크립트를 Colab 노트북에서 실행하는 경우 다음 명령을 사용하여 노트북의 일부로 내장 TensorBoard 인스턴스를 실행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 34860), started 0:30:29 ago. (Use '!kill 34860' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2aa12cca2ef58b40\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2aa12cca2ef58b40\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard 인터페이스에서는 그림 7.7에서 보는 것처럼 학습 및 평가 지표의 실시간 그래프를 모니터링할 수 있습니다.\n",
    "\n",
    "<img src=\"https://deeplearningwithpython.io/images/ch07/tensorboard.aec6cc75.png\" width=\"600\"><p style=\"text-align:center\">Figure 7.7: TensorBoard can be used for easy monitoring of training and evaluation metrics.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own training and evaluation loops\n",
    "\n",
    "`fit()` 워크플로는 사용 편의성과 유연성 사이에서 훌륭한 균형을 이루고 있습니다. 대부분의 경우 이 워크플로를 사용하게 될 것입니다. 하지만 이 워크플로는 딥러닝 연구자가 원하는 모든 기능을 지원하도록 설계된 것은 아닙니다. 사용자 정의 메트릭, 손실 함수, 콜백 함수 등을 사용하더라도 마찬가지입니다.\r\n",
    "\r\n",
    "기본 제공되는 `fit()` 워크플로는 오로지 지도 학습에만 초점을 맞추고 있습니다. 지도 학습은 입력 데이터와 연결된 알려진 목표값(레이블 또는 어노테이션이라고도 함)이 있고, 손실 함수를 이러한 목표값과 모델의 예측값의 함수로 계산하는 방식입니다. 그러나 모든 머신러닝이 이 범주에 속하는 것은 아닙니다. 생성 학습(16장에서 소개), 자기 지도 학습(입력 데이터로부터 목표값을 얻는 방식), 강화 학습(강아지 훈련처럼 간헐적인 \"보상\"을 통해 학습하는 방식)과 같이 명시적인 목표값이 없는 경우도 있습니다. 또한 일반적인 지도 학습을 수행하더라도 연구자는 저수준의 유연성이 필요한 새로운 기능을 추가하고 싶을 수 있습니다.\r\n",
    "\r\n",
    "내장 함수 `fit()`만으로는 충분하지 않은 상황에 직면할 때는 직접 사용자 지정 학습 로직을 작성해야 합니다. 2장과 3장에서 이미 간단한 저수준 학습 루프 예제를 살펴보았습니다. 일반적인 학습 루프의 내용은 다음과 같습니다.\r\n",
    "\r\n",
    "현재 데이터 배치에 대한 손실 값을 얻기 위해 \"순방향 전달\"(모델 출력 계산)을 실행합니다.\r\n",
    "\r\n",
    "모델 가중치에 대한 손실의 기울기를 계산합니다.\r\n",
    "\r\n",
    "현재 데이터 배치의 손실 값을 낮추도록 모델의 가중치를 업데이트합니다.\r\n",
    "\r\n",
    "이러한 단계는 필요한 만큼의 배치에 대해 반복됩니다. 이것이 바로 `fit()` 함수가 내부적으로 수행하는 작업입니다. 이 섹션에서는 `fit()` 함수를 처음부터 다시 구현하는 방법을 배우게 되며, 이를 통해 어떤 학습 알고리즘이든 직접 작성할 수 있는 지식을 얻게 될 것입니다.\r\n",
    "\r\n",
    "자세한 내용을 살펴보겠습니다. 다음 몇 섹션에 걸쳐 TensorFlow, PyTorch 및 JAX를 사용하여 완전한 기능을 갖춘 맞춤형 학습 루프를 작성하는 단계까지 진행하게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training vs. inference\n",
    "\n",
    "지금까지 살펴본 저수준 학습 루프 예제에서 1단계(순방향 전달)는 `predictions = model(inputs)`를 통해 수행되었고, 2단계(그래디언트 테이프에서 계산된 그래디언트를 가져오는 것)는 백엔드별 API를 통해 수행되었습니다. 예를 들어 다음과 같습니다.\r\n",
    "\r\n",
    "* TensorFlow: `gradients = tape.gradient(loss, model.weights)`\r\n",
    "* PyTorch: `loss.backward()`\r\n",
    "* JAX: `jax.value_and_grad()`\r\n",
    "\r\n",
    "일반적인 경우에는 고려해야 할 두 가지 미묘한 차이가 있습니다.\r\n",
    "\r\n",
    "Dropout 레이어와 같은 일부 Keras 레이어는 학습 중과 추론(예측을 생성하는 데 사용) 중에 동작 방식이 다릅니다. 이러한 레이어는 `call()` 메서드에 `training`이라는 부울 인수를 제공합니다. `dropout(inputs, training=True)`를 호출하면 일부 활성화 항목이 제거되고, `dropout(inputs, training=False)`를 호출하면 아무 작업도 수행되지 않습니다. 마찬가지로 함수형 모델과 순차형 모델도 `call()` 메서드에 이 `training` 인수를 제공합니다. Keras 모델을 순방향 전달(forward pass) 중에 호출할 때는 `training=True`를 반드시 전달해야 합니다! 따라서 순방향 전달 코드는 `predictions = model(inputs, training=True)`가 됩니다.\r\n",
    "\r\n",
    "또한, 모델 가중치의 기울기를 가져올 때는 `model.weights`가 아닌 `model.trainable_weights`를 사용해야 합니다. 레이어와 모델은 두 가지 종류의 가중치를 가집니다.\r\n",
    "\r\n",
    "* 첫째, 역전파를 통해 모델의 손실을 최소화하도록 업데이트되는 학습 가능 가중치(trainable weights)입니다. 예를 들어, Dense 레이어의 커널과 바이어스가 여기에 해당합니다.\r\n",
    "\r\n",
    "* 둘째, 순방향 전달 중에 해당 레이어에서 업데이트되는 학습 불가능 가중치(non-trainable weights)입니다. 예를 들어, 특정 레이어가 지금까지 처리한 배치 수를 카운터로 저장하려면, 이 정보는 학습 불가능 가중치에 저장되고, 각 배치마다 레이어는 카운터를 1씩 증가시킵니다.\r\n",
    "\r\n",
    "케라스 내장 레이어 중 학습 불가능한 가중치를 사용하는 유일한 레이어는 9장에서 소개할 배치 정규화(BatchNormalization) 레이어입니다. 배치 정규화 레이어는 통과하는 데이터의 평균과 표준 편차에 대한 정보를 추적하기 위해 학습 불가능한 가중치가 필요하며, 이를 통해 특징 정규화(4장과 6장에서 배운 개념)를 온라인으로 근사화합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Writing custom training step functions\n",
    "\n",
    "이 두 가지 사항을 고려하면 지도 학습 훈련 단계는 의사 코드로 다음과 같이 표현됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs, targets):\n",
    "    # Runs the forward pass\n",
    "    predictions = model(inputs, training=True)\n",
    "    # Computes the loss for the current batch\n",
    "    loss = loss_fn(targets, predictions)\n",
    "    # Retrieves the gradients of the loss with regard to the model's\n",
    "    # trainable weights This function doesn't actually exist!\n",
    "    gradients = get_gradients_of(loss, wrt=model.trainable_weights)\n",
    "    # Updates the model's trainable weights based on the gradients\n",
    "    optimizer.apply(gradients, model.trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 코드 조각은 가상의 함수 `get_gradients_of()`를 포함하고 있기 때문에 실제 코드가 아닌 의사 코드입니다. 실제로는 기울기를 가져오는 방식은 사용하는 백엔드(JAX, TensorFlow 또는 PyTorch)에 따라 다릅니다.\r\n",
    "\r\n",
    "이제 3장에서 각 프레임워크에 대해 배운 내용을 바탕으로 `train_step()` 함수의 실제 버전을 구현해 보겠습니다. TensorFlow와 PyTorch는 비교적 쉽게 구현할 수 있으므로 이 두 프레임워크부터 시작하는 것이 좋습니다. 마지막으로 좀 더 복잡한 JAX를 다뤄보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### A TensorFlow training step function\n",
    "\n",
    "TensorFlow를 사용하면 저희가 제시한 의사 코드 조각과 거의 유사한 코드를 작성할 수 있습니다. 유일한 차이점은 순방향 전달이 GradientTape 스코프 내에서 이루어져야 한다는 것입니다. 그런 다음 테이프 객체를 사용하여 기울기를 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = get_mnist_model()\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply(gradients, model.trainable_weights)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 단계만 실행해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "inputs = train_images[:batch_size]\n",
    "targets = train_labels[:batch_size]\n",
    "loss = train_step(inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### A PyTorch training step function\n",
    "\n",
    "PyTorch 백엔드를 사용하면 모든 Keras 레이어와 모델은 PyTorch의 `torch.nn.Module` 클래스를 상속받고 네이티브 모듈 API를 노출합니다. 결과적으로 모델, 학습 가능한 가중치, 손실 텐서는 모두 서로를 인식하고 `loss.backward()`, `weight.value.grad`, `model.zero_grad()`라는 세 가지 메서드를 통해 상호 작용합니다.\r\n",
    "\r\n",
    "3장에서 설명했듯이, 기억해야 할 핵심 모델은 다음과 같습니다.\r\n",
    "\r\n",
    "PyTorch는 순방향 전달을 할 때마다 방금 수행된 계산을 추적하는 일회성 계산 그래프를 구축합니다.\r\n",
    "\r\n",
    "이 그래프의 특정 스칼라 노드(예: 손실 텐서)에서 `.backward()`를 호출하면 해당 노드에서 시작하여 그래프를 역방향으로 실행하고, 관련된 모든 텐서(requires_grad=True인 경우)에 출력 노드의 기울기를 나타내는 `tensor.grad` 속성을 자동으로 채웁니다. 특히 학습 가능한 매개변수의 `grad` 속성이 채워집니다.\r\n",
    "\r\n",
    "텐서의 `tensor.grad` 속성 내용을 지우려면 모든 텐서에 대해 `tensor.grad = None`을 호출해야 합니다. 모든 모델 변수에 대해 개별적으로 이 작업을 수행하는 것은 다소 번거롭기 때문에 `model.zero_grad()`를 통해 모델 수준에서 한 번에 처리할 수 있습니다. `zero_grad()` 호출은 모델이 추적하는 모든 변수에 적용됩니다. `backward()` 호출은 가산 방식으로 이루어지기 때문에 기울기를 지우는 것은 매우 중요합니다. 각 단계에서 기울기를 지우지 않으면 기울기 값이 누적되어 학습이 진행되지 않습니다.\r\n",
    "이제 이러한 단계를 순서대로 진행해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m get_mnist_model()\n\u001b[0;32m      4\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = get_mnist_model()\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    # Runs the forward pass\n",
    "    predictions = model(inputs, training=True)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "    # Runs the backward pass, populating gradient values\n",
    "    loss.backward()\n",
    "    # Recovers the gradient associated with each trainable variable.\n",
    "    # That weight.value is the PyTorch tensor that contains the\n",
    "    # variable's value.\n",
    "    gradients = [weight.value.grad for weight in model.trainable_weights]\n",
    "    # Updates the model's trainable weights based on the gradients.\n",
    "    # This must be done in a no_grad() scope.\n",
    "    with torch.no_grad():\n",
    "        optimizer.apply(gradients, model.trainable_weights)\n",
    "    # Don't forget to clear the gradients!\n",
    "    model.zero_grad()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 단계만 실행해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%%backend torch\n",
    "batch_size = 32\n",
    "inputs = train_images[:batch_size]\n",
    "targets = train_labels[:batch_size]\n",
    "loss = train_step(inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### A JAX training step function\n",
    "\n",
    "저수준 학습 코드 작성에 있어서 JAX는 완전한 상태 비저장 특성 때문에 세 가지 백엔드 중 가장 복잡한 경향이 있습니다. 상태 비저장 특성 덕분에 JAX는 높은 성능과 확장성을 제공하며, 컴파일 및 자동 성능 최적화에 적합합니다. 하지만 상태 비저장 코드를 작성하려면 몇 가지 단계를 거쳐야 합니다.\r\n",
    "\r\n",
    "기울기 함수는 메타프로그래밍을 통해 얻어지므로, 먼저 손실 값을 반환하는 함수를 정의해야 합니다. 또한, 이 함수는 상태를 저장하지 않아야 하므로 사용할 모든 변수를 인수로 받아야 하고, 업데이트된 변수의 값을 반환해야 합니다. 순방향 전달 과정에서 수정될 수 있는 학습 불가능한 가중치들을 기억하시나요? 바로 이러한 변수들을 반환해야 합니다.\r\n",
    "\r\n",
    "JAX의 상태 비저장 프로그래밍 패러다임을 더 쉽게 사용할 수 있도록 Keras 모델은 상태 비저장 순방향 전달 메서드인 `stateless_call()`을 제공합니다. 이 메서드는 `__call__` 메서드와 동작 방식이 동일하지만, 다음과 같은 차이점이 있습니다.\r\n",
    "\r\n",
    "* 입력값으로 모델의 학습 가능 가중치와 학습 불가능 가중치, 그리고 입력값과 학습 인자를 받습니다.\r\n",
    "\r\n",
    "* 반환값으로는 모델의 출력값과 함께 업데이트된 학습 불가능 가중치를 반환합니다.\r\n",
    "\r\n",
    "작동 방식은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, non_trainable_weights = model.stateless_call(\n",
    "    trainable_weights, non_trainable_weights, inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stateless_call()을 사용하여 JAX 손실 함수를 구현할 수 있습니다. 손실 함수는 학습 불가능한 모든 변수에 대한 업데이트도 계산하므로 compute_loss_and_updates()라고 이름을 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# Gradients are computed for the entries in the first argument\n",
    "# (trainable_variables here)\n",
    "def compute_loss_and_updates(\n",
    "    trainable_variables, non_trainable_variables, inputs, targets\n",
    "):\n",
    "    # Calls stateless_call\n",
    "    outputs, non_trainable_variables = model.stateless_call(\n",
    "        trainable_variables, non_trainable_variables, inputs, training=True\n",
    "    )\n",
    "    loss = loss_fn(targets, outputs)\n",
    "    # Returns the scalar loss value and the updated non-trainable\n",
    "    # weights\n",
    "    return loss, non_trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute_loss_and_updates() 함수를 얻은 후에는 이 함수를 jax.value_and_grad에 전달하여 기울기 계산 결과를 얻을 수 있습니다.\n",
    "\n",
    "```\n",
    "import jax\r\n",
    "\r\n",
    "grad_fn = jax.value_and_grad(fn)\r\n",
    "loss, gradients = grad_fn(.\n",
    "```\n",
    "자, 이제 작은 문제가 하나 있습니다. jax.grad()와 jax.value_and_grad() 모두 fn이 스칼라 값만 반환해야 합니다. compute_loss_and_updates() 함수는 첫 번째 출력으로 스칼라 값을 반환하지만, 학습 불가능한 가중치에 대한 새로운 값도 함께 반환합니다. 3장에서 배운 내용을 기억하시나요? 해결책은 grad() 또는 value_and_grad() 함수에 has_aux 인수를 전달하는 것입니다. 다음과 같이 하면 됩니다...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jax'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[131], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\n\u001b[0;32m      3\u001b[0m grad_fn \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvalue_and_grad(compute_loss_and_updates, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jax'"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "grad_fn = jax.value_and_grad(compute_loss_and_updates, has_aux=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용 방법은 다음과 같습니다.\n",
    "```\n",
    "(loss, non_trainable_weights), gradients = grad_fn(\r\n",
    "    trainable_variables, non_trainable_variables, inputs, targets\r\n",
    "```\n",
    "네, 지금까지 JAX 관련 내용이 많았지만, 이제 JAX 학습 단계를 구성하는 데 필요한 거의 모든 것을 갖췄습니다. 마지막으로 필요한 것은 optimizer.apply()입니다.\r\n",
    "\r\n",
    "2장 초반에 TensorFlow로 첫 번째 기본 학습 단계를 작성했을 때, 다음과 같은 업데이트 단계 함수를 작성했었죠.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    for g, w in zip(gradients, weights):\n",
    "        w.assign(w - g * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이는 `keras.optimizers.SGD` 옵티마이저가 수행하는 작업과 유사합니다. 하지만 Keras API의 다른 모든 옵티마이저는 이보다 다소 복잡하며 학습 속도를 높이는 데 도움이 되는 보조 변수를 추적합니다. 특히 대부분의 옵티마이저는 2장에서 다룬 모멘텀 개념을 사용합니다. 이러한 추가 변수는 학습의 각 단계에서 업데이트되며, JAX 환경에서는 이러한 변수를 인수로 받아 새로운 값을 반환하는 상태 비저장 함수가 필요합니다.\r\n",
    "\r\n",
    "이를 쉽게 하기 위해 Keras는 모든 옵티마이저에서 `stateless_apply()` 메서드를 제공합니다. 이 메서드는 다음과 같이 작동합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_variables, optimizer_variables = optimizer.stateless_apply(\n",
    "    optimizer_variables, grads, trainable_variables\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 우리는 완벽한 교육 과정을 구성하는 데 필요한 모든 것을 갖추었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%%backend jax\n",
    "optimizer = keras.optimizers.Adam()\n",
    "optimizer.build(model.trainable_variables)\n",
    "\n",
    "# The state is part of the function arguments.\n",
    "def train_step(state, inputs, targets):\n",
    "    # Unpacks the state\n",
    "    (trainable_variables, non_trainable_variables, optimizer_variables) = state\n",
    "    # Computes gradients and updates to non-trainable variables\n",
    "    (loss, non_trainable_variables), grads = grad_fn(\n",
    "        trainable_variables, non_trainable_variables, inputs, targets\n",
    "    )\n",
    "    # Updates trainable variables and optimizer variables\n",
    "    trainable_variables, optimizer_variables = optimizer.stateless_apply(\n",
    "        optimizer_variables, grads, trainable_variables\n",
    "    )\n",
    "    return loss, (\n",
    "        # Returns the updated state alongside the loss\n",
    "        trainable_variables,\n",
    "        non_trainable_variables,\n",
    "        optimizer_variables,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 단계만 실행해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%%backend jax\n",
    "batch_size = 32\n",
    "inputs = train_images[:batch_size]\n",
    "targets = train_labels[:batch_size]\n",
    "\n",
    "trainable_variables = [v.value for v in model.trainable_variables]\n",
    "non_trainable_variables = [v.value for v in model.non_trainable_variables]\n",
    "optimizer_variables = [v.value for v in optimizer.variables]\n",
    "\n",
    "state = (trainable_variables, non_trainable_variables, optimizer_variables)\n",
    "loss, state = train_step(state, inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow나 PyTorch보다 확실히 작업량이 조금 더 많지만, JAX의 속도와 확장성이라는 장점이 그 단점을 충분히 상쇄합니다.\r\n",
    "\r\n",
    "다음으로, 사용자 지정 학습 루프의 또 다른 중요한 요소인 메트릭에 대해 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Low-level usage of metrics\n",
    "\n",
    "저수준 학습 루프에서는 Keras 메트릭(사용자 정의 메트릭이든 내장 메트릭이든)을 사용하는 것이 좋습니다. 메트릭 API에 대해서는 이미 배웠습니다. 각 목표 및 예측 배치에 대해 update_state(y_true, y_pred)를 호출하고 result()를 사용하여 현재 메트릭 값을 조회하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "from keras import ops\n",
    "\n",
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = ops.array([0, 1, 2])\n",
    "predictions = ops.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 손실과 같은 스칼라 값의 평균을 추적해야 할 수도 있습니다. 이 경우 `keras.metrics.Mean` 메트릭을 사용하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "values = ops.array([0, 1, 2, 3, 4])\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 에포크 시작 시 또는 평가 시작 시 현재 결과를 초기화하려면 `metric.reset_state()`를 사용하는 것을 잊지 마세요.\r\n",
    "\r\n",
    "JAX를 사용하는 경우 `update_state()` 또는 `reset()`과 같은 상태 수정 메서드는 스테이트리스 함수 내에서 사용할 수 없습니다. 대신, 이전에 학습한 `model.stateless_call()` 및 `optimizer.stateless_apply()` 메서드와 유사한 스테이트리스 메트릭 API를 사용할 수 있습니다. 작동 방식은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = ops.array([0, 1, 2])\n",
    "predictions = ops.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "\n",
    "metric_variables = metric.variables\n",
    "metric_variables = metric.stateless_update_state(\n",
    "    metric_variables, targets, predictions\n",
    ")\n",
    "current_result = metric.stateless_result(metric_variables)\n",
    "print(f\"result: {current_result:.2f}\")\n",
    "\n",
    "metric_variables = metric.stateless_reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Using fit() with a custom training loop\n",
    "\n",
    "이전 섹션에서는 학습 로직을 처음부터 직접 작성했습니다. 이렇게 하면 가장 큰 유연성을 얻을 수 있지만, 많은 코드를 작성해야 할 뿐만 아니라 `fit()`의 콜백, 성능 최적화, 분산 학습 지원과 같은 편리한 기능을 활용할 수 없게 됩니다.\r\n",
    "\r\n",
    "사용자 지정 학습 알고리즘이 필요하지만 Keras의 내장 학습 루프 기능도 사용하고 싶다면 어떻게 해야 할까요? `fit()`과 직접 작성한 학습 루프 사이에는 중간 지점이 있습니다. 바로 사용자 지정 학습 단계 함수를 제공하고 프레임워크가 나머지를 처리하도록 하는 것입니다.\r\n",
    "\r\n",
    "이는 `Model` 클래스의 `train_step()` 메서드를 오버라이드하여 구현할 수 있습니다. 이 함수는 `fit()`이 데이터 배치마다 호출하는 함수입니다. 이렇게 하면 평소처럼 `fit()`을 호출할 수 있으며, 내부적으로는 사용자 지정 학습 알고리즘이 실행됩니다.\r\n",
    "\r\n",
    "작동 방식은 다음과 같습니다.\r\n",
    "\r\n",
    "* `keras.Model`을 상속하는 새 클래스를 생성합니다.\r\n",
    "\r\n",
    "* `train_step()` 메서드를 오버라이드합니다.` 내용은 이전 섹션에서 사용한 것과 거의 동일합니다.\r\n",
    "* 메트릭 이름(손실 포함)과 현재 값을 매핑하는 딕셔너리를 반환합니다.\r\n",
    "\r\n",
    "다음 사항에 유의하세요.\r\n",
    "\r\n",
    "* 이 패턴은 함수형 API를 사용하여 모델을 구축하는 것을 막지 않습니다. 순차 모델, 함수형 API 모델 또는 서브클래싱된 모델을 구축하는 경우 모두 가능합니다.\r\n",
    "* train_step()을 재정의할 때 @tf.function 또는 @jax.jit 데코레이터를 사용할 필요가 없습니다. 프레임워크에서 자동으로 처리해 줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### Customizing fit() with TensorFlow\n",
    "먼저 사용자 정의 TensorFlow 학습 단계를 코딩해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "# This metric object will be used to track the average of per-batch\n",
    "# losses during training and evaluation.\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    # Overrides the train_step() method\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            # We use self(inputs, training=True) instead of\n",
    "            # model(inputs, training=True) since our model is the class\n",
    "            # itself.\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply(gradients, self.trainable_weights)\n",
    "\n",
    "        # Updates the loss tracker metric that tracks the average of\n",
    "        # the loss\n",
    "        loss_tracker.update_state(loss)\n",
    "        # Returns the average loss so far by querying the loss tracker\n",
    "        # metric\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    # Listing the loss tracker metric in the model.metrics property\n",
    "    # enables the model to automatically call reset_state() on it at\n",
    "    # the start of each epoch and at the start of a call to evaluate()\n",
    "    # — so you don't have to do it by hand. Any metric you would like\n",
    "    # to reset across epochs should be listed here.\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 사용자 정의 모델을 인스턴스화하고 컴파일할 수 있습니다(손실 함수는 모델 외부에서 이미 정의되어 있으므로 옵티마이저만 전달합니다). 그런 다음 평소처럼 `fit()` 함수를 사용하여 학습시킬 수 있습니다.\r\n",
    "\r\n",
    "이제 모델 정의를 재사용 가능한 별도의 함수로 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def get_custom_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = CustomModel(inputs, outputs)\n",
    "    model.compile(optimizer=keras.optimizers.Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한번 시도해 봅시다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.2932\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.1471\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.1151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2716d40ad20>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_custom_model()\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### Customizing fit() with PyTorch\n",
    "\n",
    "다음은 PyTorch 버전입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%%backend torch\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        # Runs the forward pass\n",
    "        predictions = self(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "\n",
    "        # Retrieves the gradients\n",
    "        loss.backward()\n",
    "        trainable_weights = [v for v in self.trainable_weights]\n",
    "        gradients = [v.value.grad for v in trainable_weights]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Updates weights\n",
    "            self.optimizer.apply(gradients, trainable_weights)\n",
    "\n",
    "        # Updates loss tracker metric\n",
    "        loss_tracker.update_state(loss)\n",
    "        # Returns the average loss so far by querying the loss tracker\n",
    "        # metric\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한번 해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%%backend torch\n",
    "def get_custom_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = CustomModel(inputs, outputs)\n",
    "    model.compile(optimizer=keras.optimizers.Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%%backend torch\n",
    "model = get_custom_model()\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### Customizing fit() with JAX\n",
    "\n",
    "마지막으로 JAX 버전을 작성해 보겠습니다. 먼저 사용자 지정 학습 단계 예제에서 사용했던 compute_loss_and_updates() 함수와 유사한 compute_loss_and_updates() 메서드를 정의해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%%backend jax\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def compute_loss_and_updates(\n",
    "        self,\n",
    "        trainable_variables,\n",
    "        non_trainable_variables,\n",
    "        inputs,\n",
    "        targets,\n",
    "        training=False,\n",
    "    ):\n",
    "        predictions, non_trainable_variables = self.stateless_call(\n",
    "            trainable_variables,\n",
    "            non_trainable_variables,\n",
    "            inputs,\n",
    "            training=training,\n",
    "        )\n",
    "        loss = loss_fn(targets, predictions)\n",
    "        return loss, non_trainable_variables\n",
    "\n",
    "    def train_step(self, state, data):\n",
    "        (\n",
    "            trainable_variables,\n",
    "            non_trainable_variables,\n",
    "            optimizer_variables,\n",
    "            metrics_variables,\n",
    "        ) = state\n",
    "        inputs, targets = data\n",
    "\n",
    "        grad_fn = jax.value_and_grad(\n",
    "            self.compute_loss_and_updates, has_aux=True\n",
    "        )\n",
    "\n",
    "        (loss, non_trainable_variables), grads = grad_fn(\n",
    "            trainable_variables,\n",
    "            non_trainable_variables,\n",
    "            inputs,\n",
    "            targets,\n",
    "            training=True,\n",
    "        )\n",
    "\n",
    "        (\n",
    "            trainable_variables,\n",
    "            optimizer_variables,\n",
    "        ) = self.optimizer.stateless_apply(\n",
    "            optimizer_variables, grads, trainable_variables\n",
    "        )\n",
    "\n",
    "        logs = {\"loss\": loss}\n",
    "        state = (\n",
    "            trainable_variables,\n",
    "            non_trainable_variables,\n",
    "            optimizer_variables,\n",
    "            metrics_variables,\n",
    "        )\n",
    "        return logs, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고로, 다른 두 백엔드에서처럼 손실의 이동 평균을 계산하지 않습니다. 대신 배치별 손실 값을 반환하는데, 이는 유용성이 떨어집니다. 이렇게 하는 이유는 예제에서 메트릭 상태 관리를 단순화하기 위해서입니다. 메트릭 상태 관리를 포함하면 코드가 매우 장황해지기 때문입니다(메트릭 관리에 대해서는 다음 섹션에서 자세히 설명합니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%%backend jax\n",
    "def get_custom_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = CustomModel(inputs, outputs)\n",
    "    model.compile(optimizer=keras.optimizers.Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%%backend jax\n",
    "model = get_custom_model()\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Handling metrics in a custom train_step()\n",
    "\n",
    "마지막으로, compile() 함수에 전달할 수 있는 손실 함수와 메트릭은 무엇일까요? compile() 함수를 호출한 후에는 다음과 같은 값들을 사용할 수 있습니다.\r\n",
    "\r\n",
    "* self.compute_loss — compile() 함수에 전달한 손실 함수와 특정 레이어에서 추가될 수 있는 정규화 손실을 합산한 값입니다.\r\n",
    "* self.metrics — compile() 함수에 전달한 메트릭 목록입니다. 여기에는 손실을 추적하는 메트릭도 포함됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### train_step() metrics handling with TensorFlow\n",
    "\n",
    "TensorFlow를 사용하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%%backend tensorflow\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compute_loss(y=targets, y_pred=predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply(gradients, self.trainable_weights)\n",
    "\n",
    "        for metric in self.metrics:\n",
    "            if metric.name == \"loss\":\n",
    "                metric.update_state(loss)\n",
    "            else:\n",
    "                metric.update_state(targets, predictions)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%%backend tensorflow\n",
    "def get_custom_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = CustomModel(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = get_custom_model()\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### train_step() metrics handling with PyTorch\n",
    "\n",
    "PyTorch를 사용하면 어떻게 될까요? 코드 변경 사항은 완전히 동일합니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%%backend torch\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        predictions = self(inputs, training=True)\n",
    "        loss = self.compute_loss(y=targets, y_pred=predictions)\n",
    "\n",
    "        loss.backward()\n",
    "        trainable_weights = [v for v in self.trainable_weights]\n",
    "        gradients = [v.value.grad for v in trainable_weights]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.optimizer.apply(gradients, trainable_weights)\n",
    "\n",
    "        for metric in self.metrics:\n",
    "            if metric.name == \"loss\":\n",
    "                metric.update_state(loss)\n",
    "            else:\n",
    "                metric.update_state(targets, predictions)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%%backend torch\n",
    "def get_custom_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = CustomModel(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = get_custom_model()\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### train_step() metrics handling with JAX\n",
    "\n",
    "마지막으로 JAX를 사용하면 어떻게 되는지 살펴보겠습니다. 우선 compute_loss_and_updates() 메서드에서 compute_loss()를 사용하여 compile()에 전달된 손실 함수를 호출할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%%backend jax\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def compute_loss_and_updates(\n",
    "        self,\n",
    "        trainable_variables,\n",
    "        non_trainable_variables,\n",
    "        inputs,\n",
    "        targets,\n",
    "        training=False,\n",
    "    ):\n",
    "        predictions, non_trainable_variables = self.stateless_call(\n",
    "            trainable_variables,\n",
    "            non_trainable_variables,\n",
    "            inputs,\n",
    "            training=training,\n",
    "        )\n",
    "        loss = self.compute_loss(y=targets, y_pred=predictions)\n",
    "        return loss, (predictions, non_trainable_variables)\n",
    "\n",
    "    def train_step(self, state, data):\n",
    "        (\n",
    "            trainable_variables,\n",
    "            non_trainable_variables,\n",
    "            optimizer_variables,\n",
    "            metrics_variables,\n",
    "        ) = state\n",
    "        inputs, targets = data\n",
    "\n",
    "        grad_fn = jax.value_and_grad(\n",
    "            self.compute_loss_and_updates, has_aux=True\n",
    "        )\n",
    "\n",
    "        (loss, (predictions, non_trainable_variables)), grads = grad_fn(\n",
    "            trainable_variables,\n",
    "            non_trainable_variables,\n",
    "            inputs,\n",
    "            targets,\n",
    "            training=True,\n",
    "        )\n",
    "        (\n",
    "            trainable_variables,\n",
    "            optimizer_variables,\n",
    "        ) = self.optimizer.stateless_apply(\n",
    "            optimizer_variables, grads, trainable_variables\n",
    "        )\n",
    "\n",
    "        new_metrics_vars = []\n",
    "        logs = {}\n",
    "        for metric in self.metrics:\n",
    "            num_prev = len(new_metrics_vars)\n",
    "            num_current = len(metric.variables)\n",
    "            current_vars = metrics_variables[num_prev : num_prev + num_current]\n",
    "            if metric.name == \"loss\":\n",
    "                current_vars = metric.stateless_update_state(current_vars, loss)\n",
    "            else:\n",
    "                current_vars = metric.stateless_update_state(\n",
    "                    current_vars, targets, predictions\n",
    "                )\n",
    "            logs[metric.name] = metric.stateless_result(current_vars)\n",
    "            new_metrics_vars += current_vars\n",
    "\n",
    "        state = (\n",
    "            trainable_variables,\n",
    "            non_trainable_variables,\n",
    "            optimizer_variables,\n",
    "            new_metrics_vars,\n",
    "        )\n",
    "        return logs, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "많은 정보였지만, 이제 여러분은 케라스를 사용하여 거의 모든 작업을 수행할 수 있을 만큼 충분한 지식을 갖추게 되었습니다!\n",
    "\n",
    "### Summary\n",
    "\n",
    "* Keras는 점진적 복잡성 공개 원칙에 기반한 다양한 워크플로우를 제공하며, 이 워크플로우들은 모두 원활하게 상호 운용됩니다.\r\n",
    "* Sequential 클래스, Functional API 또는 Model 클래스의 서브클래싱을 통해 모델을 구축할 수 있습니다. 대부분의 경우 Functional API를 사용하게 됩니다.\r\n",
    "* 모델을 학습하고 평가하는 가장 간단한 방법은 기본 fit() 및 evaluate() 메서드를 사용하는 것입니다.\r\n",
    "* Keras 콜백은 fit() 호출 중에 모델을 모니터링하고 모델 상태에 따라 자동으로 작업을 수행하는 간단한 방법을 제공합니다.\r\n",
    "* 또한, JAX, TensorFlow 또는 PyTorch와 같은 원하는 백엔드의 API를 사용하여 train_step() 메서드를 재정의함으로써 fit() 메서드의 동작을 완벽하게 제어할 수 있습니다.\r\n",
    "* fit() 메서드 외에도 백엔드 네이티브 방식으로 처음부터 완전히 새로운 학습 루프를 직접 작성할 수도 있습니다. 이는 완전히 새로운 학습 알고리즘을 구현하는 연구자에게 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_deep-dive-keras",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
